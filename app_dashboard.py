# -*- coding: utf-8 -*-
"""
ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ëŒ€ì‹œë³´ë“œ (Aì•ˆ: st.data_editor ê¸°ë°˜, ì»´í¬ë„ŒíŠ¸/iframe ì œê±°)
- íƒ­1: ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ
- íƒ­2: ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰
"""

# ==== ìƒë‹¨ ê³µí†µ ë¶€íŠ¸ìŠ¤íŠ¸ë© (ëª¨ë“  st.* í˜¸ì¶œë³´ë‹¤ ë¨¼ì €) ====
import os
os.environ.setdefault("STREAMLIT_CACHE_DIR", "/tmp/streamlit-cache")
os.environ.setdefault("STREAMLIT_BROWSER_GATHER_USAGE_STATS", "false")
os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")

import re
import math
import time
import datetime as dt
from typing import List, Dict, Any

import pandas as pd
import pytz
import streamlit as st
from google.cloud import firestore


# 1) ê°€ì¥ ë¨¼ì € page_config
st.set_page_config(page_title="í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼", layout="wide")


# 2) ì•ˆì „ í…Œì´ë¸” ë Œë” í—¬í¼ (AgGrid ëŒ€ì²´)
def render_safe_table(
    df: pd.DataFrame,
    key: str,
    page_size: int = 25,
    selectable: bool = True,
    auto_pick_first: bool = True,
    height: int | None = None,
    column_config: dict | None = None,
):
    """
    - data_editor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ + (ì˜µì…˜) ë‹¨ì¼í–‰ ì„ íƒ(ì²´í¬ë°•ìŠ¤)
    - ë°˜í™˜: (í˜„ì¬ í˜ì´ì§€ DF, ì„ íƒí–‰(dict)|None)
    """
    if df is None or df.empty:
        st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, None

    total = len(df)
    total_pages = (total + page_size - 1) // page_size
    page = st.number_input("Page", 1, max(1, total_pages), 1, key=f"{key}_page")
    start = (page - 1) * page_size
    end = min(start + page_size, total)
    st.caption(f"Page {page}/{total_pages} Â· Rows {start+1}-{end} / {total}")

    view = df.iloc[start:end].copy().reset_index(drop=True)

    picked_row = None
    if selectable:
        pick_col = "__pick__"
        if pick_col not in view.columns:
            view.insert(0, pick_col, False)
        if auto_pick_first and len(view) > 0:
            view.at[0, pick_col] = True

        edited = st.data_editor(
            view,
            key=f"{key}_editor_{page}",
            hide_index=True,
            use_container_width=True,
            height=height,
            column_config=column_config or {},
        )
        sel_df = edited[edited[pick_col] == True].drop(columns=[pick_col], errors="ignore")
        if not sel_df.empty:
            picked_row = sel_df.iloc[0].to_dict()
        return edited.drop(columns=[pick_col], errors="ignore"), picked_row

    else:
        st.data_editor(
            view,
            key=f"{key}_editor_{page}",
            hide_index=True,
            use_container_width=True,
            height=height,
            disabled=True,
            column_config=column_config or {},
        )
        return view, None


# ====== ìœ í‹¸ ======
TABLE_SCROLL_HEIGHT = 520
KST = pytz.timezone("Asia/Seoul")

def naver_item_url(ticker: str | None) -> str:
    t = (ticker or "").strip()
    if not t or len(t) != 6:
        return "https://finance.naver.com"
    return f"https://finance.naver.com/item/main.naver?code={t}"

def last_close_from_horizons(rec: dict) -> float | None:
    horizons = rec.get("horizons") or []
    if not horizons:
        return None
    try:
        horizons = sorted(horizons, key=lambda h: h.get("end_date",""))
    except Exception:
        pass
    last_close = None
    for h in horizons:
        ps = h.get("price_sample") or []
        closes = [p.get("close") for p in ps if p.get("close") is not None]
        if closes:
            last_close = float(closes[-1])
    return last_close

def normalize_broker_name(name: str) -> str:
    if not name:
        return ""
    name = re.sub(r"\s+", "", name)
    name = re.sub(r"[&/\.#\[\]]", "_", name)
    name = re.sub(r"[\(\)\[\]]", "", name)
    return name.strip()

def normalize_analyst_name(name: str) -> str:
    if not name:
        return ""
    return re.sub(r"\s+", "", str(name)).strip()

def _norm_url(x: str) -> str:
    if not x:
        return ""
    s = str(x).strip()
    if s.startswith(("http://", "https://")):
        return s
    return "https://" + s

def format_ts(ts, tz=KST):
    if not ts:
        return "-"
    try:
        dt_utc = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
    except Exception:
        try:
            dt_utc = dt.datetime.fromisoformat(str(ts))
        except Exception:
            return str(ts)
    if dt_utc.tzinfo is None:
        dt_utc = dt_utc.replace(tzinfo=dt.timezone.utc)
    return dt_utc.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S %Z")

def _aggrid_selected_empty(sel) -> bool:
    # ì‚¬ìš© ì¤‘ë‹¨(í˜¸í™˜ ìœ„í•´ ë‚¨ê¹€): ì´ì œ render_safe_tableì´ ì„ íƒ ì²˜ë¦¬
    return True

def _aggrid_pick_first(sel):
    return None


# -----------------------------
# Firestore Client
# -----------------------------
@st.cache_resource(show_spinner=False)
def get_db():
    return firestore.Client()

@st.cache_data(show_spinner=False, ttl=300)
def fetch_titles_for_records(records: list[dict]) -> dict[str, str]:
    db = get_db()
    ids = []
    for r in records:
        rid = str(r.get("report_id") or "").strip()
        if rid:
            ids.append(rid)
    ids = sorted(set(ids))
    if not ids:
        return {}

    refs = [db.collection("analyst_reports").document(rid) for rid in ids]
    try:
        snaps = db.get_all(refs)
    except Exception:
        return {}

    out = {}
    for s in snaps:
        if not s.exists:
            continue
        d = s.to_dict() or {}
        t = (d.get("title") or d.get("report_title") or d.get("subject") or "").strip()
        if t:
            out[s.id] = t
    return out

def _pick_title(rec: dict) -> str:
    for k in ["title", "report_title", "subject", "report_subject", "headline", "name"]:
        t = (rec.get(k) or "").strip()
        if t:
            return t
    return ""

def _title_from_map_or_fields(rec: dict, title_map: dict[str, str] | None = None) -> str:
    rid = str(rec.get("report_id") or "").strip()
    if title_map and rid in title_map:
        return title_map[rid]
    t = _pick_title(rec)
    if t:
        return t
    stock = (rec.get("stock") or "").strip()
    rdate = (rec.get("report_date") or "").strip()
    return f"{stock or 'ë¦¬í¬íŠ¸'} ({rdate or '-'})"


# -----------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------
@st.cache_data(show_spinner=False, ttl=60)
def load_analyst_docs(date_from: dt.date, date_to: dt.date,
                      brokers: List[str] | None, limit: int = 3000) -> List[Dict[str, Any]]:
    db = get_db()
    docs_raw = []
    server_filtered = False
    try:
        q = db.collection_group("by_analyst")
        want_min = date_from.isoformat() if date_from else None
        want_max_excl = (date_to + dt.timedelta(days=1)).isoformat() if date_to else None

        q = db.collection_group("by_analyst")
        if want_min:     q = q.where("report_date", ">=", want_min)
        if want_max_excl:q = q.where("report_date", "<",  want_max_excl)
        q = q.limit(limit)
        docs_raw = list(q.stream())
        server_filtered = True
    except Exception:
        q = db.collection_group("by_analyst").limit(limit)
        docs_raw = list(q.stream())

    broker_set = {normalize_broker_name(b) for b in (brokers or [])} or None
    out: List[Dict[str, Any]] = []
    for d in docs_raw:
        x = d.to_dict() or {}
        broker_norm = normalize_broker_name((x.get("broker") or "").strip())
        if broker_norm == "í•œêµ­IRí˜‘ì˜íšŒ" or "í‰ê°€" in broker_norm:
            continue
        if broker_set and broker_norm not in broker_set:
            continue
        x["broker"] = broker_norm
        raw_name = (x.get("analyst_name") or x.get("analyst") or "").strip()
        x["analyst_name"] = raw_name
        x["analyst_name_norm"] = x.get("analyst_name_norm") or normalize_analyst_name(raw_name)

        if not server_filtered and (date_from or date_to):
            s = (x.get("report_date") or "").strip()
            if not s:
                continue
            try:
                d0 = dt.date.fromisoformat(s[:10])
            except Exception:
                continue
            if date_from and d0 < date_from:
                continue
            if date_to and d0 > date_to:
                continue

        if x.get("points_total") is None and x.get("horizons"):
            x["points_total"] = sum(float(h.get("points_total_this_horizon") or 0.0) for h in x.get("horizons") or [])
        out.append(x)
    return out

@st.cache_data(show_spinner=False, ttl=60)
def load_detail_for_analyst(analyst_name: str, broker: str,
                            date_from: dt.date | None, date_to: dt.date | None,
                            limit: int = 800) -> List[Dict[str, Any]]:
    db = get_db()
    out: List[Dict[str, Any]] = []
    broker_norm = normalize_broker_name(broker)
    target_norm = normalize_analyst_name(analyst_name)

    def _q(field: str, value: str):
        q = (db.collection_group("by_analyst")
               .where("broker", "==", broker_norm)
               .where(field, "==", value))
        try:
            if date_from: q = q.where("report_date", ">=", date_from.isoformat())
            if date_to:   q = q.where("report_date", "<=", date_to.isoformat())
        except Exception:
            pass
        q = q.limit(limit)
        docs = [z.to_dict() or {} for z in q.stream()]
        for z in docs:
            z["broker"] = normalize_broker_name(z.get("broker"))
            rn = (z.get("analyst_name") or z.get("analyst") or "").strip()
            z["analyst_name"] = rn
            z["analyst_name_norm"] = z.get("analyst_name_norm") or normalize_analyst_name(rn)
        return docs

    out.extend(_q("analyst_name_norm", target_norm))
    if not out:
        out.extend(_q("analyst_name", analyst_name))
        if target_norm != analyst_name:
            out.extend(_q("analyst_name", target_norm))

    seen = set(); uniq = []
    for r in out:
        key = (str(r.get("report_id","")), str(r.get("pdf_url","")))
        if key in seen:
            continue
        seen.add(key); uniq.append(r)
    uniq.sort(key=lambda r: r.get("report_date",""), reverse=True)
    return uniq


# -----------------------------
# ì§‘ê³„ & í…Œì´ë¸” ë³€í™˜
# -----------------------------
def make_rank_table(docs: list[dict], metric: str = "avg", min_reports: int = 2) -> pd.DataFrame:
    from collections import defaultdict
    agg = defaultdict(lambda: {"sum":0.0, "n":0, "name_disp":"", "broker":"", "first":None, "last":None})
    for x in docs:
        name_raw = (x.get("analyst_name") or x.get("analyst") or "").strip()
        name_norm = x.get("analyst_name_norm") or normalize_analyst_name(name_raw)
        broker = normalize_broker_name((x.get("broker") or "").strip())
        try:
            pts = float(x.get("points_total") or 0.0)
        except Exception:
            pts = 0.0
        rdate = (x.get("report_date") or "").strip()
        key = f"{name_norm}|{broker}"
        agg[key]["sum"] += pts
        agg[key]["n"] += 1
        if not agg[key]["name_disp"]:
            agg[key]["name_disp"] = name_raw or "(unknown)"
        agg[key]["broker"] = broker
        if rdate:
            if not agg[key]["first"] or rdate < agg[key]["first"]:
                agg[key]["first"] = rdate
            if not agg[key]["last"] or rdate > agg[key]["last"]:
                agg[key]["last"]  = rdate
    rows = []
    for _, v in agg.items():
        if v["n"] < min_reports: 
            continue
        score = (v["sum"]/v["n"]) if metric == "avg" else v["sum"]
        rows.append({
            "RankScore": round(score, 4),
            "Reports": v["n"],
            "Analyst": v["name_disp"],
            "Broker": v["broker"],
            "FirstReport": v["first"] or "",
            "LastReport": v["last"] or "",
        })
    if not rows:
        return pd.DataFrame(columns=["RankScore","Reports","Analyst","Broker","FirstReport","LastReport"])
    df = pd.DataFrame(rows).sort_values(["RankScore","Reports"], ascending=[False, False]).reset_index(drop=True)
    return df

def _price_stats(price_sample: list[dict] | None):
    if not price_sample:
        return None, None, None
    closes = [float(p.get("close")) for p in price_sample if p.get("close") is not None]
    if not closes:
        return None, None, None
    return max(closes), min(closes), closes[-1]

def _sign(x: float | None):
    if x is None: return None
    return 1 if x > 0 else (-1 if x < 0 else 0)

def _desired_from_horizon(h: Dict[str, Any]) -> int | None:
    dtg = h.get("direction_target") or {}
    desired = dtg.get("desired")
    try:
        return int(desired) if desired is not None else None
    except Exception:
        return None

def format_pos_label(desired: int | None, rating_norm: str | None) -> str:
    r = (rating_norm or "").lower()
    if desired == 1 or r == "buy":  return "ìƒìŠ¹(buy)"
    if desired == -1 or r == "sell": return "í•˜ë½(sell)"
    return "ì¤‘ë¦½(hold)"

def horizon_to_rows(rec: Dict[str, Any]) -> List[Dict[str, Any]]:
    rows = []
    horizons = rec.get("horizons") or []
    rating_norm = rec.get("rating_norm") or rec.get("rating")
    target_price = rec.get("target_price")

    for h in horizons:
        desired = _desired_from_horizon(h)
        ret = h.get("return_pct", None)
        actual_sign = _sign(ret)
        correct = None
        if desired is not None and actual_sign is not None:
            if desired == 0: correct = (actual_sign == 0)
            else:            correct = (desired == actual_sign)

        sample = h.get("price_sample") or []
        max_c, min_c, last_c = _price_stats(sample)

        target_return_pct = None
        if target_price and target_price not in ("", 0, 0.0) and last_c:
            try:
                target_return_pct = round((float(last_c)-float(target_price))/float(target_price)*100, 3)
            except Exception:
                target_return_pct = None

        max_reach_pct = None
        if target_price and target_price not in ("", 0, 0.0) and max_c:
            try:
                max_reach_pct = round((float(max_c)/float(target_price)-1)*100, 3)
            except Exception:
                max_reach_pct = None

        rows.append({
            "ë³´ê³ ì„œì¼": rec.get("report_date",""),
            "horizon(ì¼)": h.get("horizon_days"),
            "ì˜ˆì¸¡í¬ì§€ì…˜": format_pos_label(desired, rating_norm),
            "ë ˆì´íŒ…": rating_norm,
            "ì˜ˆì¸¡ëª©í‘œê°€": target_price,
            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %": None if ret is None else round(ret*100, 3),
            "ëª©í‘œê°€ëŒ€ë¹„ìˆ˜ìµë¥ %": target_return_pct,
            "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%": max_reach_pct,
            "ë°©í–¥ì •ë‹µ": None if correct is None else ("âœ…" if correct else "âŒ"),
            "ë°©í–¥ì ìˆ˜": h.get("direction_point", 0.0),
            "ëª©í‘œê·¼ì ‘ì ìˆ˜": h.get("target_proximity_point", 0.0),
            "ëª©í‘œê°€HIT": h.get("hit_target_anytime", None),
            "êµ¬ê°„ìµœê³ ì¢…ê°€": max_c,
            "êµ¬ê°„ìµœì €ì¢…ê°€": min_c,
            "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€": last_c,
            "ì¢…ëª©": rec.get("stock",""),
            "í‹°ì»¤": rec.get("ticker",""),
            "ë¦¬í¬íŠ¸PDF": rec.get("pdf_url","") or rec.get("report_url",""),
            "ìƒì„¸í˜ì´ì§€": rec.get("detail_url",""),
            "ë¦¬í¬íŠ¸ì´ì ": rec.get("points_total", 0.0),
        })
    return rows

def match_stock(rec: dict, stock_q: str | None, ticker_q: str | None) -> bool:
    if not stock_q and not ticker_q:
        return True
    if ticker_q:
        t = (rec.get("ticker") or "").strip()
        if t and str(t).lower() == str(ticker_q).lower():
            return True
    if stock_q:
        name = (rec.get("stock") or "").strip()
        if name and str(stock_q).lower() in name.lower():
            return True
    return False

def get_last_updated_from_docs(docs):
    latest = None
    for d in docs:
        ts = d.get("updated_at")
        if not ts:
            continue
        try:
            t = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
        except Exception:
            try:
                t = dt.datetime.fromisoformat(str(ts))
            except Exception:
                continue
        if latest is None or t > latest:
            latest = t
    return latest


# -----------------------------
# Streamlit UI
# -----------------------------
st.title("ğŸ“Š ì¢…ëª©ë¦¬í¬íŠ¸ ë¶„ì„")

# --- Tabs ìŠ¤íƒ€ì¼ (ê¸°ì¡´ ìœ ì§€) ---
st.markdown("""
<style>
div[data-testid="stTabs"] div[role="tablist"] {
  border-bottom: 2px solid #e9ecef; gap: 8px; padding-bottom: 2px; margin-bottom: 8px;
}
div[data-testid="stTabs"] button[role="tab"] {
  font-weight: 600; font-size: 0.95rem; color: #495057;
  background: #f8f9fa; border: 1px solid #e9ecef; border-bottom: none;
  border-top-left-radius: 8px; border-top-right-radius: 8px;
  padding: 10px 14px; box-shadow: inset 0 -3px 0 0 rgba(0,0,0,0.03);
}
div[data-testid="stTabs"] button[role="tab"]:hover { background: #f1f3f5; color: #343a40; }
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"] {
  background: #ffffff; color: #212529; border-color: #dee2e6; box-shadow: inset 0 -4px 0 0 #0d6efd;
}
div[data-testid="stTabs"] > div[data-baseweb="tab-panel"] {
  border: 1px solid #dee2e6; border-top: none; border-radius: 0 10px 10px 10px;
  padding: 16px 16px 10px 16px; background: #ffffff;
}
div[data-testid="stTabs"] button[role="tab"] p { line-height: 1.1; margin: 0; }
</style>
""", unsafe_allow_html=True)

# ---- ì‚¬ì´ë“œë°” ----
with st.sidebar:
    st.header("ê³µí†µ í•„í„°")
    today = dt.date.today()
    default_from = today - dt.timedelta(days=90)
    date_from = st.date_input("From date", value=default_from)
    date_to = st.date_input("To date", value=today)

    metric = st.radio("Ranking metric", ["avg", "sum"], index=0, horizontal=True)
    min_reports = st.slider("Minimum reports", 1, 20, 2, 1)
    max_docs = st.slider("Max docs to scan (by_analyst)", 500, 5000, 3000, 100)

    st.caption("â€» ê¸°ê°„/ë¸Œë¡œì»¤ë¥¼ ì¢íìˆ˜ë¡ ë¹ ë¦…ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë¦¬í¬íŠ¸ë³„ points_total í•©ê³„(ë˜ëŠ” í‰ê· )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    base_docs = load_analyst_docs(date_from, date_to, brokers=None, limit=max_docs)
    broker_counts = {}
    for d in base_docs:
        b = normalize_broker_name((d.get("broker") or "").strip())
        if not b:
            continue
        broker_counts[b] = broker_counts.get(b, 0) + 1
    available_brokers = sorted([b for b, c in broker_counts.items() if c > 0])

    st.markdown("### ì¦ê¶Œì‚¬ ì„ íƒ")
    if not available_brokers:
        st.info("í•´ë‹¹ ê¸°ê°„ì— ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        selected_brokers = []
    else:
        labels = [f"{b} ({broker_counts[b]})" for b in available_brokers]
        selected_labels = st.multiselect("ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ ëª©ë¡", options=labels, default=labels, key="multi_brokers")
        selected_brokers = [lab.split(" (")[0] for lab in selected_labels if " (" in lab]
        if not selected_brokers:
            st.warning("ì„ íƒëœ ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# ---- ë°ì´í„° ë¡œë“œ (ë‘ íƒ­ì—ì„œ ê³µí†µ ì‚¬ìš©) ----
with st.spinner("ë¬¸ì„œ ë¡œë”© ì¤‘..."):
    docs = load_analyst_docs(date_from, date_to, selected_brokers or None, max_docs)

# âš ï¸ ë©´ì±… ì¡°í•­
st.markdown("---")
st.markdown(
    """
    âš ï¸ **ë©´ì±… ì¡°í•­ (Disclaimer)**
    ë³¸ ì‚¬ì´íŠ¸ëŠ” **í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼ í•™ìƒë“¤ì˜ ì‹¤ìŠµ ëª©ì **ìœ¼ë¡œ ì œì‘ëœ ê²ƒì…ë‹ˆë‹¤.
    ë”°ë¼ì„œ ì œê³µë˜ëŠ” ë°ì´í„°ì™€ ë­í‚¹ì€ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì–´ë– í•œ ê³µì‹ ë ¥ë„ ê°–ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ë˜í•œ, ë³¸ ì‚¬ì´íŠ¸ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **íˆ¬ì ê²°ì • ë° ê·¸ ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ ì „ì ìœ¼ë¡œ ì´ìš©ì ë³¸ì¸**ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
    ì œì‘ìëŠ” íˆ¬ì ì†ì‹¤ ë“± ì–´ë– í•œ ë²•ì  ì±…ì„ë„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """,
    unsafe_allow_html=True
)

# í‰ê°€ ë°˜ì˜ ê¸°ê°„ ë° ìµœê·¼ ê°±ì‹  ì‹œê°
date_values = [str(d.get("report_date", "")).strip() for d in docs if str(d.get("report_date","")).strip()]
if date_values:
    try:
        min_date = min(date_values)
        max_date = max(date_values)
        st.markdown(f"**í‰ê°€ ë°˜ì˜ ê¸°ê°„** {min_date} ~ {max_date}")
    except Exception:
        st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")
else:
    st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")

st.caption(f"ìµœê·¼ í‰ê°€ ë°˜ì˜ ì‹œê°(ë¬¸ì„œ ê¸°ì¤€): {format_ts(get_last_updated_from_docs(docs))}")

# -----------------------------
# ì˜¤ëŠ˜ ë²”ìœ„ ì‹ ì„ ë„ ë°°ë„ˆ + íƒ­2 ë³‘í•© ë°ì´í„° ì¤€ë¹„
# -----------------------------
today = dt.date.today()
is_today_range = (date_from and date_to and date_from <= today <= date_to)

if is_today_range:
    by_cnt = sum(1 for d in docs if str(d.get("report_date","")).startswith(today.isoformat()))
    db = get_db()
    ar_cnt = len(list(db.collection("analyst_reports")
                      .where("pred_time", ">=", today.isoformat())
                      .where("pred_time", "<",  (today + dt.timedelta(days=1)).isoformat())
                      .stream()))
    if ar_cnt > by_cnt:
        st.warning(f"ì˜¤ëŠ˜ ë°ì´í„° ë™ê¸°í™” ì§„í–‰ ì¤‘: by_analyst {by_cnt}ê±´ / analyst_reports {ar_cnt}ê±´")

docs_for_stock = docs[:]
if is_today_range:
    db = get_db()
    iso_min = date_from.isoformat()
    iso_max_excl = (date_to + dt.timedelta(days=1)).isoformat()
    try:
        q_ar = (db.collection("analyst_reports")
                  .where("pred_time", ">=", iso_min)
                  .where("pred_time", "<",  iso_max_excl)
                  .limit(max_docs))
        rows = [s.to_dict() or {} for s in q_ar.stream()]
    except Exception:
        rows = []

    seen = set((
        str(x.get("report_id") or ""),
        normalize_broker_name(x.get("broker") or ""),
        (x.get("analyst_name") or x.get("analyst") or "").strip(),
        str(x.get("report_date") or "")
    ) for x in docs_for_stock)

    for x in rows:
        rd = (x.get("report_date") or x.get("pred_time") or "")
        x["report_date"] = str(rd)[:10] if rd else ""
        b = normalize_broker_name(x.get("broker") or "")
        if b == "í•œêµ­IRí˜‘ì˜íšŒ":
            continue
        x["broker"] = b
        a_raw = (x.get("analyst_name") or x.get("analyst") or "").strip()
        x["analyst_name"] = a_raw
        x["analyst_name_norm"] = x.get("analyst_name_norm") or normalize_analyst_name(a_raw)
        k = (str(x.get("report_id") or ""), b, a_raw, x["report_date"])
        if k in seen:
            continue
        seen.add(k)
        docs_for_stock.append(x)

# -----------------------------
# Tabs
# -----------------------------
tab_rank, tab_stock = st.tabs(["ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ", "ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰"])

# ===============================
# íƒ­1: ë­í‚¹ë³´ë“œ (í˜ì´ì§€ë„¤ì´ì…˜ + ë‹¨ì¼ ì„ íƒ)
# ===============================
with tab_rank:
    st.subheader("ğŸ† Top Analysts")
    rank_df = make_rank_table(docs, metric=metric, min_reports=min_reports)

    if rank_df.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„/ë¸Œë¡œì»¤/ìµœì†Œ ë¦¬í¬íŠ¸ ìˆ˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
    else:
        per_page = st.selectbox("Rows per page", [10, 25, 50, 100], index=1, key="rank_rows_per_page")

        # ë°ì´í„° ì—ë””í„°ë¡œ êµì²´
        _show_df = rank_df.reset_index(drop=True).copy()
        rank_view, rank_pick = render_safe_table(
            _show_df,
            key="rank_table",
            page_size=per_page,
            selectable=True,
            auto_pick_first=False,
            height=None,
        )

        if not rank_pick:
            st.info("ìƒë‹¨ í‘œì—ì„œ ì²´í¬ë°•ìŠ¤ë¡œ í–‰ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            picked_name = rank_pick.get("Analyst", "Unknown Analyst")
            picked_broker = rank_pick.get("Broker", "Unknown Broker")
            st.markdown(f"### {picked_name} â€” {picked_broker}")
            st.write(f"**Reports:** {rank_pick.get('Reports', '-') } | **RankScore:** {rank_pick.get('RankScore', '-') }")
            st.write(f"**Coverage:** {rank_pick.get('FirstReport', '-') } â†’ {rank_pick.get('LastReport', '-') }")

            with st.spinner("Loading evidence..."):
                items = load_detail_for_analyst(picked_name, picked_broker, date_from, date_to)

            if not items:
                st.info("ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                evidence_rows: List[Dict[str, Any]] = []
                for it in items:
                    evidence_rows.extend(horizon_to_rows(it))
                ev_df = pd.DataFrame(evidence_rows)

                wanted = [
                    "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
                    "horizon(ì¼)",
                    "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",
                    "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
                    "ë¦¬í¬íŠ¸ì´ì ", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"
                ]
                cols = [c for c in wanted if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted]
                ev_df = ev_df[cols]

                colcfg = {
                    "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                    "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                }
                # ìƒì„¸í‘œëŠ” ì„ íƒ ë¶ˆí•„ìš” â†’ disabled ëª¨ë“œ
                render_safe_table(
                    ev_df, key="rank_evidence_table",
                    page_size=50, selectable=False, height=TABLE_SCROLL_HEIGHT,
                    column_config=colcfg
                )

# ===============================
# íƒ­2: ì¢…ëª©ë³„ ê²€ìƒ‰
# ===============================
if "stock_q" not in st.session_state:
    st.session_state["stock_q"] = ""
if "ticker_q" not in st.session_state:
    st.session_state["ticker_q"] = ""

with tab_stock:
    st.subheader("ğŸ” ì¢…ëª©ë³„ ë¦¬í¬íŠ¸ ì¡°íšŒ")
    col1, col2 = st.columns([2,1])

    stock_q = st.text_input("ì¢…ëª©ëª…(ë¶€ë¶„ì¼ì¹˜ í—ˆìš©)", key="stock_q", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
    ticker_q = st.text_input("í‹°ì»¤(ì •í™•íˆ 6ìë¦¬)", key="ticker_q", placeholder="ì˜ˆ: 005930")

    candidates = []
    if stock_q.strip():
        seen = set()
        for d in docs_for_stock:
            s = (d.get("stock") or "").strip()
            t = str(d.get("ticker") or "").strip()
            if s and stock_q.lower() in s.lower():
                key = (s, t)
                if key not in seen:
                    seen.add(key)
                    label = f"{s} ({t})" if t else s
                    candidates.append({"label": label, "stock": s, "ticker": t})
        candidates.sort(key=lambda x: (x["stock"], x["ticker"]))

    selected_stock = None
    selected_ticker = None
    if candidates:
        if len(candidates) == 1:
            selected_stock = candidates[0]["stock"]
            selected_ticker = (candidates[0]["ticker"] or "").strip() or None
            st.session_state["last_stock_pick"] = candidates[0]["label"]
        else:
            opt_labels = [c["label"] for c in candidates]
            default_index = 0
            if "last_stock_pick" in st.session_state and st.session_state["last_stock_pick"] in opt_labels:
                default_index = opt_labels.index(st.session_state["last_stock_pick"])
            pick = st.selectbox("í›„ë³´ ì¢…ëª© ì„ íƒ", options=opt_labels, index=default_index, key="cand_pick")
            st.session_state["last_stock_pick"] = pick
            _picked = next((c for c in candidates if c["label"] == pick), None)
            if _picked:
                selected_stock = _picked["stock"]
                selected_ticker = (_picked["ticker"] or "").strip() or None

    if selected_stock:
        _sel_tk = (selected_ticker or "").strip()
        stock_docs = [
            d for d in docs_for_stock
            if (d.get("stock") or "").strip() == selected_stock
            and (not _sel_tk or str(d.get("ticker") or "").strip() == _sel_tk)
        ]
        st.markdown(f"**ê²€ìƒ‰ ëŒ€ìƒ:** {selected_stock} ({selected_ticker or '-'})")
    else:
        if not stock_q.strip() and not ticker_q.strip():
            stock_docs = docs_for_stock
            st.caption("ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤.")
        else:
            stock_docs = [d for d in docs_for_stock if match_stock(d, stock_q or None, ticker_q or None)]
            if candidates:
                st.caption(f"í›„ë³´ ì¢…ëª© {len(candidates)}ê°œ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

    st.caption(f"ê²€ìƒ‰ê²°ê³¼: {len(stock_docs)}ê±´ (ê¸°ê°„Â·ì¦ê¶Œì‚¬ í•„í„° ì ìš© í›„ ì¢…ëª© í•„í„°)")

    if not stock_docs:
        st.info("í•´ë‹¹ ì¡°ê±´ì˜ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ëª©ëª…/í‹°ì»¤ ë˜ëŠ” ê¸°ê°„/ì¦ê¶Œì‚¬ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
    else:
        from collections import defaultdict

        # 1) ì¦ê¶Œì‚¬ ìš”ì•½
        by_broker = defaultdict(lambda: {"reports":0, "analysts":set(), "first":None, "last":None})
        for x in stock_docs:
            b = (x.get("broker") or "").strip()
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            by_broker[b]["reports"] += 1
            if a: by_broker[b]["analysts"].add(a)
            if d0:
                if by_broker[b]["first"] is None or d0 < by_broker[b]["first"]:
                    by_broker[b]["first"] = d0
                if by_broker[b]["last"] is None or d0 > by_broker[b]["last"]:
                    by_broker[b]["last"] = d0
        broker_rows = [{
            "ì¦ê¶Œì‚¬": b,
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜": len(v["analysts"]),
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for b, v in by_broker.items()]
        broker_df = pd.DataFrame(broker_rows).sort_values(["ë¦¬í¬íŠ¸ìˆ˜","ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜"], ascending=[False, False])
        st.markdown("### 1) ì¦ê¶Œì‚¬ë³„ ìš”ì•½")
        render_safe_table(broker_df, key="stock_broker_summary", page_size=25, selectable=False, height=None)

        # 2) ì• ë„ë¦¬ìŠ¤íŠ¸ ìš”ì•½
        st.markdown("### 2) ì• ë„ë¦¬ìŠ¤íŠ¸ë³„ ìš”ì•½")
        brokers_for_select = sorted({(x.get("broker") or "").strip() for x in stock_docs if x.get("broker")})
        pick_broker = st.selectbox("ì¦ê¶Œì‚¬ ì„ íƒ", ["(ëª¨ë‘)"] + brokers_for_select, index=0, key="stock_pick_broker")
        docs2 = stock_docs if pick_broker == "(ëª¨ë‘)" else [x for x in stock_docs if (x.get("broker") or "").strip() == pick_broker]

        by_anl = defaultdict(lambda: {"reports":0, "sum_pts":0.0, "first":None, "last":None})
        for x in docs2:
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            pts = float(x.get("points_total") or 0.0)
            by_anl[a]["reports"] += 1
            by_anl[a]["sum_pts"] += pts
            if d0:
                if by_anl[a]["first"] is None or d0 < by_anl[a]["first"]:
                    by_anl[a]["first"] = d0
                if by_anl[a]["last"] is None or d0 > by_anl[a]["last"]:
                    by_anl[a]["last"] = d0
        anl_rows = [{
            "ì• ë„ë¦¬ìŠ¤íŠ¸": a or "(unknown)",
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "í‰ê· ì ìˆ˜": round(v["sum_pts"]/v["reports"], 4) if v["reports"] else 0.0,
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for a, v in by_anl.items()]
        anl_df = pd.DataFrame(anl_rows).sort_values(["í‰ê· ì ìˆ˜","ë¦¬í¬íŠ¸ìˆ˜"], ascending=[False, False]).reset_index(drop=True)
        render_safe_table(anl_df, key="stock_anl_summary", page_size=25, selectable=False, height=None)

        # 3) ìƒì„¸ ë‚´ì—­
        st.markdown("### 3) ìƒì„¸ ë‚´ì—­")
        detail_rows = []
        title_map_stock = fetch_titles_for_records(stock_docs)
        for r in stock_docs:
            title_safe = _title_from_map_or_fields(r, title_map_stock) or f'{(r.get("stock") or "").strip()} ë¦¬í¬íŠ¸'
            try:
                last_close = last_close_from_horizons(r)
            except Exception:
                last_close = None
            detail_rows.append({
                "ë¦¬í¬íŠ¸ì¼": r.get("report_date",""),
                "ì¦ê¶Œì‚¬": r.get("broker",""),
                "ì• ë„ë¦¬ìŠ¤íŠ¸": r.get("analyst_name") or r.get("analyst",""),
                "ì¢…ëª©": r.get("stock",""),
                "ë ˆì´íŒ…": r.get("rating") or r.get("rating_norm",""),
                "ëª©í‘œê°€": r.get("target_price"),
                "ë§ˆì§€ë§‰ì¢…ê°€": last_close,
                "ì œëª©": title_safe,
            })
        det_df = pd.DataFrame(detail_rows).sort_values("ë¦¬í¬íŠ¸ì¼", ascending=False).reset_index(drop=True)

        if det_df.empty:
            st.info("ìƒë‹¨ í‘œì—ì„œ í–‰ì„ ì„ íƒí•˜ì„¸ìš”.")
        else:
            page_size = st.selectbox("ìƒì„¸ ë‚´ì—­ í˜ì´ì§€ í¬ê¸°", options=[25, 50, 100, 200], index=1, key="detail_page_size")
            det_view, det_pick = render_safe_table(
                det_df,
                key="stock_detail_main_table_safe",
                page_size=page_size,
                selectable=True,
                auto_pick_first=True,
                height=TABLE_SCROLL_HEIGHT,
            )

            if det_pick:
                st.markdown("---")
                st.markdown("#### ğŸ“Œ ì„ íƒ ë¦¬í¬íŠ¸ ìƒì„¸")

                p_stock  = det_pick.get("ì¢…ëª©","")
                p_ticker = ""
                # í‹°ì»¤ ì¶”ì •(ì›ë³¸ docsì—ì„œ ì¢…ëª©ëª… ë§¤ì¹­)
                for _r in stock_docs:
                    t = str(_r.get("ticker") or "").strip()
                    s = (_r.get("stock") or "").strip()
                    if s == p_stock and t:
                        p_ticker = t
                        break
                p_broker = det_pick.get("ì¦ê¶Œì‚¬","")
                p_anl    = det_pick.get("ì• ë„ë¦¬ìŠ¤íŠ¸","")
                p_date   = det_pick.get("ë¦¬í¬íŠ¸ì¼","")

                c1, c2, c3, c4 = st.columns([2,2,2,2])
                c1.markdown(f"**ì¢…ëª©/í‹°ì»¤**: {p_stock} ({p_ticker or '-'})")
                c2.markdown(f"**ì¦ê¶Œì‚¬**: {p_broker}")
                c3.markdown(f"**ì• ë„ë¦¬ìŠ¤íŠ¸**: {p_anl}")
                c4.markdown(f"**ë¦¬í¬íŠ¸ì¼**: {p_date}")

                st.markdown("#### ğŸ“„ í•´ë‹¹ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ê·¼ê±° ë‚´ì—­")
                with st.spinner("ì• ë„ë¦¬ìŠ¤íŠ¸ ìƒì„¸ ë¡œë”©..."):
                    items = load_detail_for_analyst(p_anl, p_broker, date_from, date_to)
                    reports_n = len(items)
                    total_pts = 0.0
                    dates = []
                    for it in items:
                        try:
                            total_pts += float(it.get("points_total") or 0.0)
                        except Exception:
                            pass
                        rd = (it.get("report_date") or "").strip()
                        if rd: dates.append(rd)

                    rank_score = (total_pts / reports_n) if reports_n and metric == "avg" else total_pts
                    cov_first = min(dates) if dates else "-"
                    cov_last  = max(dates) if dates else "-"
                    st.write(f"**Reports:** {reports_n}  |  **RankScore:** {round(rank_score, 4) if reports_n else 0.0}  |  **Coverage:** {cov_first} â†’ {cov_last}")

                if items:
                    rows_ev = []
                    for it in items:
                        rows_ev.extend(horizon_to_rows(it))
                    ev_df = pd.DataFrame(rows_ev)

                    wanted_cols = [
                        "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
                        "horizon(ì¼)",
                        "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",
                        "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
                        "ë¦¬í¬íŠ¸ì´ì ", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"
                    ]
                    cols = [c for c in wanted_cols if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted_cols]
                    ev_df = ev_df[cols]

                    colcfg = {
                        "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                        "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                    }
                    render_safe_table(
                        ev_df, key="stock_detail_evidence_table",
                        page_size=50, selectable=False, height=TABLE_SCROLL_HEIGHT,
                        column_config=colcfg
                    )
                else:
                    st.info("ì„ íƒí•œ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ìƒì„¸ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                st.markdown("#### ğŸ“ˆ ì¢…ëª© ì •ë³´")
                st.markdown(f"[ë„¤ì´ë²„ ê¸ˆìœµ ìƒì„¸ ë³´ê¸°]({naver_item_url(p_ticker)})")
