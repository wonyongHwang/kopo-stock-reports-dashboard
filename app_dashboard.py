# -*- coding: utf-8 -*-
"""
Analyst Ranking & Evidence Dashboard (Horizon-only)
- ìƒìœ„ ë­ì»¤ë¥¼ ë°”ë¡œ ë³´ì—¬ì£¼ê³ , í´ë¦­ ì‹œ ê·¼ê±°(ë¦¬í¬íŠ¸ URL/ì˜ˆì¸¡ê°€/í¬ì§€ì…˜/ì‹¤ì œ ì„±ê³¼)ë¥¼ í…Œì´ë¸”ë¡œ ë…¸ì¶œ
- 30/60ì¼ ì„±ê³¼ ì„¹ì…˜ì€ ì œê±° (ìš”ì²­ì‚¬í•­)
- Firestore êµ¬ì¡°ëŠ” evaluations/by_analyst ì €ì¥ ìŠ¤í‚¤ë§ˆì— ë§ì¶¤
"""

import math
import datetime as dt
from typing import List, Dict, Any, Tuple

import streamlit as st
import pandas as pd
import datetime as dt
import pytz

from google.cloud import firestore

# app_dashboard.py ìƒë‹¨ì— ì „ì—­ ì„¤ì • ì¶”ê°€
EXCLUDED_BROKERS = {"í•œêµ­IRí˜‘ì˜íšŒ"}  # ì œì™¸í•  ì¦ê¶Œì‚¬ëª… ì§‘í•©

def is_allowed_broker(broker: str) -> bool:
    return broker not in EXCLUDED_BROKERS

# íŒŒì¼ ìƒë‹¨ í—¬í¼ë“¤ ê·¼ì²˜ì— ì¶”ê°€
def _norm_url(x: str) -> str:
    if not x:
        return ""
    s = str(x).strip()
    if s.startswith(("http://", "https://")):
        return s
    # ìŠ¤í‚´ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ https ê°€ì •
    return "https://" + s



KST = pytz.timezone("Asia/Seoul")

def format_ts(ts, tz=KST):
    """Firestore Timestamp ë˜ëŠ” ë¬¸ìì—´/None â†’ ë³´ê¸°ìš© ë¬¸ìì—´"""
    if not ts:
        return "-"
    try:
        # Firestore Timestamp -> datetime
        dt_utc = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
    except Exception:
        # '2025-09-05' ê°™ì€ ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìŒ
        try:
            dt_utc = dt.datetime.fromisoformat(str(ts))
        except Exception:
            return str(ts)
    if dt_utc.tzinfo is None:
        dt_utc = dt_utc.replace(tzinfo=dt.timezone.utc)
    return dt_utc.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S %Z")
# ===============================
# Firestore Client & Caches
# ===============================
@st.cache_resource(show_spinner=False)
def get_db():
    return firestore.Client()

@st.cache_data(show_spinner=False, ttl=60)
def load_broker_list() -> List[str]:
    """by_analyst ê·¸ë£¹ì—ì„œ broker ëª©ë¡ ì¶”ì¶œ"""
    db = get_db()
    q = db.collection_group("by_analyst").select(["broker"]).limit(3000)
    s = set()
    try:
        for d in q.stream():
            b = (d.to_dict() or {}).get("broker")
            if b:
                s.add(b)
    except Exception:
        pass
    return sorted(s)

@st.cache_data(show_spinner=False, ttl=60)
def load_analyst_docs(min_date: dt.date | None, max_date: dt.date | None,
                      brokers: List[str] | None,
                      limit: int = 3000) -> List[Dict[str, Any]]:
    """
    by_analyst ë¬¸ì„œ ë¡œë“œ (í•„ìš”í•œ í•„í„°ë§Œ ì„œë²„ ì¸¡ where, ë‚˜ë¨¸ì§€ëŠ” í´ë¼ì´ì–¸íŠ¸ í•„í„°)
    """
    db = get_db()
    q = db.collection_group("by_analyst")
    try:
        if min_date: q = q.where("report_date", ">=", min_date.isoformat())
        if max_date: q = q.where("report_date", "<=", max_date.isoformat())
        q = q.limit(limit)
        docs = list(q.stream())
    except Exception:
        # ì¸ë±ìŠ¤ ì´ìŠˆ ì‹œ ë²”ìœ„ë¥¼ ì¤„ì—¬ì„œë¼ë„ ì½ê¸°
        q = db.collection_group("by_analyst").limit(limit)
        docs = list(q.stream())

    out: List[Dict[str, Any]] = []
    broker_set = set(brokers or [])
    for d in docs:
        x = d.to_dict() or {}
        broker = (x.get("broker") or "").strip()
        if not is_allowed_broker(broker):
            continue   # â† ì œì™¸
        if broker_set and (x.get("broker") or "") not in broker_set:
            continue
        # êµ¬í˜• í˜¸í™˜: points_total ì—†ìœ¼ë©´ horizon í•©ìœ¼ë¡œ ëŒ€ì²´
        if x.get("points_total") is None and x.get("horizons"):
            x["points_total"] = sum(float(h.get("points_total_this_horizon") or 0.0) for h in x.get("horizons") or [])
        out.append(x)
    return out

@st.cache_data(show_spinner=False, ttl=60)
def load_detail_for_analyst(analyst_name: str, broker: str,
                            date_from: dt.date | None, date_to: dt.date | None,
                            limit: int = 800) -> List[Dict[str, Any]]:
    """
    íŠ¹ì • ì• ë„ë¦¬ìŠ¤íŠ¸(ì´ë¦„+ë¸Œë¡œì»¤)ì˜ by_analyst ë¬¸ì„œ ëª©ë¡ ë¡œë“œ
    """
    db = get_db()
    out: List[Dict[str, Any]] = []
    q = (db.collection_group("by_analyst")
           .where("broker", "==", broker)
           .where("analyst_name", "==", analyst_name))
    try:
        if date_from: q = q.where("report_date", ">=", date_from.isoformat())
        if date_to:   q = q.where("report_date", "<=", date_to.isoformat())
    except Exception:
        pass
    q = q.limit(limit)
    for d in q.stream():
        out.append(d.to_dict() or {})
    out.sort(key=lambda r: r.get("report_date",""), reverse=True)
    return out

# ===============================
# Helpers (í‘œí˜„/ì§‘ê³„)
# ===============================
# (ìƒë‹¨ helpers ê·¼ì²˜ì— ì¶”ê°€)
def _price_stats(price_sample: list[dict]) -> tuple[float|None, float|None, float|None]:
    """
    price_sample: [{"date": "...", "open":.., "high":.., "low":.., "close":..}, ...]
    return: (max_close, min_close, last_close)
    """
    if not price_sample:
        return None, None, None
    closes = [float(p.get("close")) for p in price_sample if p.get("close") is not None]
    if not closes:
        return None, None, None
    max_c = max(closes)
    min_c = min(closes)
    last_c = closes[-1]
    return max_c, min_c, last_c

def normalize_name(s: str) -> str:
    return (s or "").strip()

def _sign(x: float | None) -> int | None:
    if x is None:
        return None
    if x > 0: return 1
    if x < 0: return -1
    return 0

def _desired_from_horizon(h: Dict[str, Any]) -> int | None:
    dtg = h.get("direction_target") or {}
    desired = dtg.get("desired")
    try:
        return int(desired) if desired is not None else None
    except Exception:
        return None

def format_pos_label(desired: int | None, rating_norm: str | None) -> str:
    r = (rating_norm or "").lower()
    if desired == 1 or r == "buy":  return "ìƒìŠ¹(buy)"
    if desired == -1 or r == "sell": return "í•˜ë½(sell)"
    return "ì¤‘ë¦½(hold)"

# ê¸°ì¡´ horizon_to_rows ë¥¼ ì•„ë˜ë¡œ êµì²´
def horizon_to_rows(rec: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    by_analyst í•œ ë¬¸ì„œ(= í•œ ë¦¬í¬íŠ¸) â†’ ì—¬ëŸ¬ horizon ê·¼ê±° í–‰ìœ¼ë¡œ í¼ì¹¨
    - ê¸°ì¡´ return_pct (= start_close ëŒ€ë¹„ end_close ë³€í™”ìœ¨)
    - ì¶”ê°€: ëª©í‘œê°€ ëŒ€ë¹„ ìˆ˜ìµë¥ % (= (end_close - target_price)/target_price )
    """
    rows = []
    horizons = rec.get("horizons") or []
    rating_norm = rec.get("rating_norm") or rec.get("rating")
    target_price = rec.get("target_price")

    for h in horizons:
        desired = _desired_from_horizon(h)
        ret = h.get("return_pct", None)  # start_close ëŒ€ë¹„ end_close ìˆ˜ìµë¥ 
        actual_sign = _sign(ret)
        correct = None
        if desired is not None and actual_sign is not None:
            if desired == 0:
                correct = (actual_sign == 0)
            else:
                correct = (desired == actual_sign)

        price_sample = h.get("price_sample") or []
        max_c, min_c, last_c = _price_stats(price_sample)

        # ëª©í‘œê°€ ëŒ€ë¹„ ìˆ˜ìµë¥  (ë§ˆì§€ë§‰ ì¢…ê°€ ê¸°ì¤€)
        target_return_pct = None
        if target_price and target_price not in ("", 0, 0.0) and last_c:
            try:
                target_return_pct = round((float(last_c) - float(target_price)) / float(target_price) * 100, 3)
            except Exception:
                target_return_pct = None

        # ëª©í‘œê°€ ëŒ€ë¹„ ìµœëŒ€ ë„ë‹¬ë¥  (ìµœê³ ê°€ ê¸°ì¤€)
        max_reach_pct = None
        if target_price and target_price not in ("", 0, 0.0) and max_c:
            try:
                max_reach_pct = round((float(max_c) / float(target_price) - 1) * 100, 3)
            except Exception:
                max_reach_pct = None

        rows.append({
            "ë³´ê³ ì„œì¼": rec.get("report_date",""),
            "horizon(ì¼)": h.get("horizon_days"),
            "ì˜ˆì¸¡í¬ì§€ì…˜": format_pos_label(desired, rating_norm),
            "ë ˆì´íŒ…": rating_norm,
            "ì˜ˆì¸¡ëª©í‘œê°€": target_price,

            # ê¸°ì¡´ ìˆ˜ìµë¥  (ë¦¬í¬íŠ¸ ì‹œì‘ ëŒ€ë¹„)
            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %": None if ret is None else round(ret*100, 3),

            # ì‹ ê·œ: ëª©í‘œê°€ ëŒ€ë¹„
            "ëª©í‘œê°€ëŒ€ë¹„ìˆ˜ìµë¥ %": target_return_pct,
            "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%": max_reach_pct,

            "ë°©í–¥ì •ë‹µ": None if correct is None else ("âœ…" if correct else "âŒ"),
            "ë°©í–¥ì ìˆ˜": h.get("direction_point", 0.0),
            "ëª©í‘œê·¼ì ‘ì ìˆ˜": h.get("target_proximity_point", 0.0),
            "ëª©í‘œê°€HIT": h.get("hit_target_anytime", None),

            "êµ¬ê°„ìµœê³ ì¢…ê°€": max_c,
            "êµ¬ê°„ìµœì €ì¢…ê°€": min_c,
            "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€": last_c,

            "ì¢…ëª©": rec.get("stock",""),
            "í‹°ì»¤": rec.get("ticker",""),
            "ì œëª©": rec.get("title",""),
            "ë¦¬í¬íŠ¸PDF": rec.get("pdf_url","") or rec.get("report_url",""),
            "ìƒì„¸í˜ì´ì§€": rec.get("detail_url",""),
            "ë¦¬í¬íŠ¸ì´ì ": rec.get("points_total", 0.0),
        })
    return rows



# def make_rank_table(docs: List[Dict[str, Any]],
#                     metric: str = "avg", min_reports: int = 2) -> pd.DataFrame:
#     """
#     ì• ë„ë¦¬ìŠ¤íŠ¸ë³„ ì§‘ê³„ â†’ ë­í‚¹í‘œ ìƒì„±
#     metric: "avg" | "sum"
#     """
#     from collections import defaultdict
#     agg = defaultdict(lambda: {"sum":0.0, "n":0, "name":"", "broker":"", "first":None, "last":None})
#     for x in docs:
#         name = normalize_name(x.get("analyst_name","")) or "(unknown)"
#         broker = x.get("broker","")
#         pts = float(x.get("points_total") or 0.0)
#         rdate = x.get("report_date","")

#         key = f"{name}|{broker}"
#         agg[key]["sum"] += pts
#         agg[key]["n"] += 1
#         agg[key]["name"] = name
#         agg[key]["broker"] = broker
#         if rdate:
#             if not agg[key]["first"] or rdate < agg[key]["first"]:
#                 agg[key]["first"] = rdate
#             if not agg[key]["last"]  or rdate > agg[key]["last"]:
#                 agg[key]["last"]  = rdate

#     rows = []
#     for k,v in agg.items():
#         if v["n"] < min_reports:  # ìµœì†Œ ë¦¬í¬íŠ¸ ìˆ˜
#             continue
#         score = (v["sum"]/v["n"]) if metric=="avg" else v["sum"]
#         rows.append({
#             "RankScore": round(score,4),
#             "Reports": v["n"],
#             "Analyst": v["name"],
#             "Broker": v["broker"],
#             "FirstReport": v["first"] or "",
#             "LastReport": v["last"] or "",
#         })
#     df = pd.DataFrame(rows).sort_values(["RankScore","Reports"], ascending=[False, False]).reset_index(drop=True)
#     df.index = df.index + 1  # 1-based rank
#     return df

def make_rank_table(docs: list[dict], metric: str = "avg", min_reports: int = 2) -> pd.DataFrame:
    from collections import defaultdict
    agg = defaultdict(lambda: {"sum":0.0, "n":0, "name":"", "broker":"", "first":None, "last":None})

    # 0) ì…ë ¥ì´ ë¹„ë©´ ì¦‰ì‹œ ë¹ˆ DF ë°˜í™˜
    if not docs:
        return pd.DataFrame(columns=["RankScore","Reports","Analyst","Broker","FirstReport","LastReport"])

    # 1) ì§‘ê³„
    for x in docs:
        name = (x.get("analyst_name") or "").strip() or "(unknown)"
        broker = (x.get("broker") or "").strip()
        try:
            pts = float(x.get("points_total") or 0.0)
        except Exception:
            pts = 0.0
        rdate = (x.get("report_date") or "").strip()

        key = f"{name}|{broker}"
        agg[key]["sum"] += pts
        agg[key]["n"] += 1
        agg[key]["name"] = name
        agg[key]["broker"] = broker
        if rdate:
            if not agg[key]["first"] or rdate < agg[key]["first"]:
                agg[key]["first"] = rdate
            if not agg[key]["last"] or rdate > agg[key]["last"]:
                agg[key]["last"]  = rdate

    # 2) ìˆœìœ„í–‰ ìƒì„±
    rows = []
    for k, v in agg.items():
        if v["n"] < min_reports:
            continue
        score = (v["sum"]/v["n"]) if metric == "avg" else v["sum"]
        rows.append({
            "RankScore": round(score, 4),
            "Reports": v["n"],
            "Analyst": v["name"],
            "Broker": v["broker"],
            "FirstReport": v["first"] or "",
            "LastReport": v["last"] or "",
        })

    # 3) rowsê°€ ë¹„ë©´ ì•ˆì „í•˜ê²Œ ë¹ˆ DF ë°˜í™˜ (ì •ë ¬ ì‹œ KeyError ë°©ì§€)
    if not rows:
        return pd.DataFrame(columns=["RankScore","Reports","Analyst","Broker","FirstReport","LastReport"])

    df = pd.DataFrame(rows)
    # 4) í˜¹ì‹œë¼ë„ ì»¬ëŸ¼ ëˆ„ë½ ì‹œ ë°©ì–´
    if not {"RankScore","Reports"}.issubset(df.columns):
        return df.reset_index(drop=True)

    return df.sort_values(["RankScore","Reports"], ascending=[False, False]).reset_index(drop=True)

def get_last_updated_from_docs(docs):
    latest = None
    for d in docs:
        ts = d.get("updated_at")
        if ts is None:
            continue
        # Firestore Timestamp ë¹„êµ
        try:
            t = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
        except Exception:
            # ë¬¸ìì—´ì¼ ìˆ˜ë„ ìˆìŒ
            try:
                t = dt.datetime.fromisoformat(str(ts))
            except Exception:
                continue
        if latest is None or t > latest:
            latest = t
    return latest

# ===============================
# Streamlit UI
# ===============================
st.set_page_config(page_title="í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼", layout="wide")
st.title("ğŸ“Š ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ")

# ---- ë©´ì±… ì¡°í•­ ----
st.markdown("---")
st.markdown(
    """
    âš ï¸ **ë©´ì±… ì¡°í•­ (Disclaimer)**
    ë³¸ ì‚¬ì´íŠ¸ëŠ” **í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼ í•™ìƒë“¤ì˜ ì‹¤ìŠµ ëª©ì **ìœ¼ë¡œ ì œì‘ëœ ê²ƒì…ë‹ˆë‹¤.
    ë”°ë¼ì„œ ì œê³µë˜ëŠ” ë°ì´í„°ì™€ ë­í‚¹ì€ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì–´ë– í•œ ê³µì‹ ë ¥ë„ ê°–ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ë˜í•œ, ë³¸ ì‚¬ì´íŠ¸ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **íˆ¬ì ê²°ì • ë° ê·¸ ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ ì „ì ìœ¼ë¡œ ì´ìš©ì ë³¸ì¸ì—ê²Œ** ìˆìŠµë‹ˆë‹¤.
    ì œì‘ìëŠ” íˆ¬ì ì†ì‹¤ ë“± ì–´ë– í•œ ë²•ì  ì±…ì„ë„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """,
    unsafe_allow_html=True
)

# Sidebar Filters
# with st.sidebar:
#     st.header("Filters")
#     today = dt.date.today()
#     default_from = today - dt.timedelta(days=365)
#     date_from = st.date_input("From date", value=default_from)
#     date_to = st.date_input("To date", value=today)
#     brokers = load_broker_list()
#     sel_brokers = st.multiselect("Brokers", brokers, default=[])
#     metric = st.radio("Ranking metric", ["avg", "sum"], index=0, horizontal=True)
#     min_reports = st.slider("Minimum reports", 1, 20, 2, 1)
#     max_docs = st.slider("Max docs to scan (by_analyst)", 500, 5000, 3000, 100)
#     st.caption("â€» ê¸°ê°„/ë¸Œë¡œì»¤ë¥¼ ì¢íìˆ˜ë¡ ë¹ ë¦…ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë¦¬í¬íŠ¸ë³„ points_total í•©ê³„(ë˜ëŠ” í‰ê· )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
# ---- ê¸°ì¡´ ì‚¬ì´ë“œë°” ì¼ë¶€ êµì²´ ----
with st.sidebar:
    st.header("Filters")
    today = dt.date.today()
    default_from = today - dt.timedelta(days=365)
    date_from = st.date_input("From date", value=default_from)
    date_to = st.date_input("To date", value=today)

    metric = st.radio("Ranking metric", ["avg", "sum"], index=0, horizontal=True)
    min_reports = st.slider("Minimum reports", 1, 20, 2, 1)
    max_docs = st.slider("Max docs to scan (by_analyst)", 500, 5000, 3000, 100)
    st.caption("â€» ê¸°ê°„/ë¸Œë¡œì»¤ë¥¼ ì¢íìˆ˜ë¡ ë¹ ë¦…ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë¦¬í¬íŠ¸ë³„ points_total í•©ê³„(ë˜ëŠ” í‰ê· )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # âŠ ë¨¼ì € ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œë§Œ ë¬¸ì„œ ë¡œë“œ â†’ ì´ìš© ê°€ëŠ¥í•œ ë¸Œë¡œì»¤ ì§‘í•©/ê±´ìˆ˜ ê³„ì‚°
    base_docs = load_analyst_docs(date_from, date_to, brokers=None, limit=max_docs)
    broker_counts = {}
    for d in base_docs:
        b = (d.get("broker") or "").strip()
        if not b:
            continue
        broker_counts[b] = broker_counts.get(b, 0) + 1

    # ì´ìš© ê°€ëŠ¥í•œ ë¸Œë¡œì»¤ë§Œ (ê±´ìˆ˜>0) ì •ë ¬
    available_brokers = sorted([b for b, c in broker_counts.items() if c > 0])

    st.markdown("### ì¦ê¶Œì‚¬ ì„ íƒ (ê´„í˜¸ì•ˆì€ ë¦¬í¬íŠ¸ ê±´ìˆ˜)")
    if not available_brokers:
        st.info("í•´ë‹¹ ê¸°ê°„ì— ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        selected_brokers = []
    else:
        # ì „ì²´ ì„ íƒ í† ê¸€
        select_all = st.checkbox("ì „ì²´ ì„ íƒ", value=True, key="brokers_select_all")

        # â‹ ì²´í¬ë°•ìŠ¤ ë Œë”: (ì´ ê¸°ê°„ì— ë¦¬í¬íŠ¸ ìˆëŠ” ë¸Œë¡œì»¤ë§Œ) ë¼ë²¨ì— ê±´ìˆ˜ í‘œê¸°
        selected_brokers = []
        for b in available_brokers:
            label = f"{b} ({broker_counts.get(b, 0)})"
            checked = st.checkbox(label, value=select_all, key=f"broker_{b}")
            if checked:
                selected_brokers.append(b)

        # ì•„ë¬´ ê²ƒë„ ì„ íƒ ì•ˆë˜ë©´ ê²½ê³  (ì§‘ê³„ëŠ” ë¹ˆ ê²°ê³¼ê°€ ë˜ë¯€ë¡œ)
        if not selected_brokers:
            st.warning("ì„ íƒëœ ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# Load
with st.spinner("Loading analyst documents..."):
    # docs = load_analyst_docs(date_from, date_to, sel_brokers or None, max_docs)
    docs = load_analyst_docs(date_from, date_to, selected_brokers or None, max_docs)
    # st.write(f"[DEBUG] loaded={len(docs)}, broker_filter={sel_brokers or '(all)'}")

last_updated = get_last_updated_from_docs(docs)
st.markdown(f"ìµœê·¼ í‰ê°€ ë°˜ì˜ ì‹œê°(ë¬¸ì„œ ê¸°ì¤€): {format_ts(last_updated)}")

# ì¶”ê°€ëœ ì½”ë“œ
# --- í‰ê°€ ë°˜ì˜ ê¸°ê°„(ë¦¬í¬íŠ¸ ë‚ ì§œ ë²”ìœ„) í‘œì‹œ ---
try:
    # docsì—ì„œ report_date ë¬¸ìì—´ë§Œ ì¶”ì¶œí•˜ì—¬ ìœ íš¨í•œ ê²ƒë“¤ë§Œ í•„í„°
    _date_vals = [str(d.get("report_date", "")).strip() for d in docs]
    _date_vals = [s for s in _date_vals if s and len(s) >= 8]  # ëŒ€ëµ 'YYYY-MM-DD' í˜•íƒœ
    if _date_vals:
        _min_date = min(_date_vals)
        _max_date = max(_date_vals)
        st.markdown(f"í‰ê°€ ë°˜ì˜ ê¸°ê°„ {_min_date} ~ {_max_date}")
    else:
        st.markdown("í‰ê°€ ë°˜ì˜ ê¸°ê°„ - ~ -")
except Exception:
    st.markdown("í‰ê°€ ë°˜ì˜ ê¸°ê°„ - ~ -")
# --- End ---

# Rank table (shown immediately)
st.subheader("ğŸ† Top Analysts")
rank_df = make_rank_table(docs, metric=metric, min_reports=min_reports)
st.write(f"[DEBUG] after min_reports=1 -> candidates={len(rank_df)} (í˜„ì¬ ì„¤ì • min_reports={min_reports})")

if rank_df.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„/ë¸Œë¡œì»¤ í•„í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
    st.stop()

# í˜ì´ì§€ë„¤ì´ì…˜ (ê°„ë‹¨)
per_page = st.selectbox("Rows per page", [10,25,50,100], 1)
page = st.number_input("Page", 1, 9999, 1)
total_pages = max(1, math.ceil(len(rank_df)/per_page))
page = min(page, total_pages)
start, end = (page-1)*per_page, (page-1)*per_page + per_page
show_df = rank_df.iloc[start:end].copy()

st.dataframe(show_df, use_container_width=True)
st.caption(f"Page {page}/{total_pages} Â· Total analysts: {len(rank_df)}")

# Pick one analyst
st.markdown("---")
st.subheader("ğŸ” ì• ë„ë¦¬ìŠ¤íŠ¸ í´ë¦­ì‹œ í™”ë©´ í•˜ë‹¨ì— ìƒì„¸ í‰ê°€í‘œ ì¡°íšŒ ê°€ëŠ¥")

# 3ì—´ ë²„íŠ¼ UI (ì´ë¦„ + ì ìˆ˜), í´ë¦­ ì‹œ ì•„ë˜ì— ìƒì„¸ í‘œë¥¼ ì¸ë¼ì¸ìœ¼ë¡œ í‘œì‹œ
if "picked_row_idx" not in st.session_state:
    st.session_state.picked_row_idx = None

_tmp_df_btn = show_df.reset_index(drop=True).copy()
n_cols = 3
cols = st.columns(n_cols)
for i, row in _tmp_df_btn.iterrows():
    with cols[i % n_cols]:
        btn_label = f"{row.get('Analyst', 'Unknown')} Â· {row.get('RankScore', '-')}"
        if st.button(btn_label, key=f"pick_{page}_{i}", use_container_width=True):
            st.session_state.picked_row_idx = i

# ì„ íƒì´ ì—†ìœ¼ë©´ ì¤‘ë‹¨
if st.session_state.picked_row_idx is None:
    st.stop()

# ì„ íƒëœ ì• ë„ë¦¬ìŠ¤íŠ¸ íŒŒì‹±
picked = _tmp_df_btn.iloc[st.session_state.picked_row_idx]
picked_name = picked.get("Analyst", "Unknown Analyst")
picked_broker = picked.get("Broker", "Unknown Broker")

st.markdown(f"### {picked_name} â€” {picked_broker}")
st.write(f"**Reports:** {picked.get('Reports', '-') } | **RankScore:** {picked.get('RankScore', '-') }")
st.write(f"**Coverage:** {picked.get('FirstReport', '-') } â†’ {picked.get('LastReport', '-') }")

with st.spinner("Loading evidence..."):
    items = load_detail_for_analyst(picked_name, picked_broker, date_from, date_to)

if not items:
    st.info("ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ë¦¬í¬íŠ¸ë³„ Horizon ê·¼ê±°ë¥¼ ê¸¸ê²Œ í¼ì³ì„œ í•œ í…Œì´ë¸”ë¡œ êµ¬ì„±
evidence_rows: List[Dict[str, Any]] = []
for it in items:
    evidence_rows.extend(horizon_to_rows(it))

if not evidence_rows:
    st.warning("Horizon ê·¼ê±°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
else:
    ev_df = pd.DataFrame(evidence_rows)

    # ë³´ê¸° ì¢‹ê²Œ ì»¬ëŸ¼ ìˆœì„œ ì¬ë°°ì¹˜
    # ê·¼ê±°í‘œë¥¼ ë Œë”í•˜ëŠ” ë¶€ë¶„ì—ì„œ ev_df ìƒì„± í›„ ì •ë ¬ ì»¬ëŸ¼ ì§€ì •í•˜ëŠ” ë¦¬ìŠ¤íŠ¸ ê°±ì‹ 
    wanted_cols = [
    "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
    "horizon(ì¼)",

    # ë¹„êµìš© ì‹ ê·œ ì§€í‘œ
    "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",

    "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
    "ë¦¬í¬íŠ¸ì´ì ", "ì œëª©", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"]
    cols = [c for c in wanted_cols if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted_cols]
    ev_df = ev_df[cols]

    # ë§í¬ ì»¬ëŸ¼ ì •ë¦¬ (ìŠ¤í‚´ ëˆ„ë½ ëŒ€ë¹„)
    if "ë¦¬í¬íŠ¸PDF" in ev_df.columns:
        ev_df["ë¦¬í¬íŠ¸PDF"] = ev_df["ë¦¬í¬íŠ¸PDF"].map(_norm_url)
    if "ìƒì„¸í˜ì´ì§€" in ev_df.columns:
        ev_df["ìƒì„¸í˜ì´ì§€"] = ev_df["ìƒì„¸í˜ì´ì§€"].map(_norm_url)

    # Streamlit 1.23+ : LinkColumn ì‚¬ìš© (ê¶Œì¥)
    try:
        st.dataframe(
            ev_df,
            use_container_width=True,
            column_config={
                "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(
                    label="ë¦¬í¬íŠ¸PDF",
                    help="PDF ì—´ê¸°",
                    display_text="ì—´ê¸°"
                ),
                "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(
                    label="ìƒì„¸í˜ì´ì§€",
                    help="ìƒì„¸ í˜ì´ì§€ ì—´ê¸°",
                    display_text="ì—´ê¸°"
                ),
            },
        )
    except Exception:
        # êµ¬ë²„ì „ Streamlit ëŒ€ì‘: HTML í…Œì´ë¸”ë¡œ í´ë°±
        def _a(href):
            return f'<a href="{href}" target="_blank" rel="noopener noreferrer">ì—´ê¸°</a>' if href else ""
        html_df = ev_df.copy()
        if "ë¦¬í¬íŠ¸PDF" in html_df.columns:
            html_df["ë¦¬í¬íŠ¸PDF"] = html_df["ë¦¬í¬íŠ¸PDF"].map(_a)
        if "ìƒì„¸í˜ì´ì§€" in html_df.columns:
            html_df["ìƒì„¸í˜ì´ì§€"] = html_df["ìƒì„¸í˜ì´ì§€"].map(_a)

        st.markdown(
            html_df.to_html(escape=False, index=False),
            unsafe_allow_html=True
        )

    # st.caption("â€» ë§í¬ ì»¬ëŸ¼ì„ í´ë¦­í•˜ë©´ ìƒˆ íƒ­ìœ¼ë¡œ ì—´ë¦½ë‹ˆë‹¤.")


    # ë§í¬ ì»¬ëŸ¼ì€ í´ë¦­ ê°€ëŠ¥í•˜ê²Œ ë Œë”
    # st.dataframe(ev_df, use_container_width=True)
    st.caption("â€» í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼ ì‹¤ìŠµ ëª©ì ì˜ ê²°ê³¼ë¬¼ë¡œ ë°ì´í„° ì·¨í•©, ì •ì œ, ë¶„ì„ì´ ë¶€ì •í™• í•  ìˆ˜ ìˆìŒ.")
