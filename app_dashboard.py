# -*- coding: utf-8 -*-
"""
ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ëŒ€ì‹œë³´ë“œ (ì™„ì„±ë³¸; ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
- íƒ­1: ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ
- íƒ­2: ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰
"""

# 0) í‘œì¤€/í™˜ê²½ ì„¤ì • â€” Streamlit import ì „ì—
import os
os.environ.setdefault("STREAMLIT_CACHE_DIR", "/tmp/streamlit-cache")
os.environ.setdefault("STREAMLIT_BROWSER_GATHER_USAGE_STATS", "false")
os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")

# 1) Streamlit import + set_page_config (íŒŒì¼ ìµœì´ˆì˜ st.* í˜¸ì¶œ)
import streamlit as st
st.set_page_config(page_title="í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼", layout="wide")
REV = os.getenv("GIT_SHA") or os.getenv("K_REVISION") or "r1"
if st.query_params.get("_v") != REV:
    st.query_params["_v"] = REV  # URLì— ?_v=REV ì¶”ê°€ â†’ streamlitUrl íŒŒë¼ë¯¸í„°ì—ë„ ë°˜ì˜ë¨
    
# 2) ë‚˜ë¨¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import re
import math
import time
import datetime as dt
from typing import List, Dict, Any
import pandas as pd
import pytz
from google.cloud import firestore

# st_aggridëŠ” í•œ ë²ˆë§Œ ì •í™•í•œ ì´ë¦„ìœ¼ë¡œ import
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
import st_aggrid as _ag

# 3) AgGrid ì „ì—­ 1íšŒ ì›œì—… (set_page_config ì´í›„, ì–´ë–¤ UI ë Œë”ë³´ë‹¤ ë¨¼ì €)
if not hasattr(st, "_aggrid_warmed"):
    comp_dir = os.path.join(os.path.dirname(_ag.__file__), "frontend", "build")
    print("[BOOT] st_aggrid at:", os.path.dirname(_ag.__file__))
    print("[BOOT] st_aggrid frontend exists:", os.path.exists(os.path.join(comp_dir, "index.html")))
    ph = st.empty()
    with ph.container():
        AgGrid(pd.DataFrame({"_": []}), height=1, key="__aggrid_warmup__", fit_columns_on_grid_load=False)
    ph.empty()
    st._aggrid_warmed = True
    print("[BOOT] AgGrid warmup done")

# 4) (ì„ íƒ) ì´ˆê¸° í”„ë ˆì„ ë ˆì´ìŠ¤ ì™„í™”ë¥¼ ìœ„í•œ 1í”„ë ˆì„ ì§€ì—°
if not st.session_state.get("_first_paint_done"):
    time.sleep(0.1)  # 50~150ms ì‚¬ì´ ê¶Œì¥
    st.session_state["_first_paint_done"] = True

# --- ì—¬ê¸°ë¶€í„° ê¸°ì¡´ ì½”ë“œ ì´ì–´ì„œ ë¶™ì´ì„¸ìš” (ìœ í‹¸/í•¨ìˆ˜/Firestore ë“±) ---



import math
import datetime as dt
from typing import List, Dict, Any
import re
import time  # â† ì¤‘ë³µ import ì •ë¦¬ (dtëŠ” ìœ„ì—ì„œ)

import streamlit as st
import pandas as pd
import pytz
from google.cloud import firestore
import os
os.environ.setdefault("STREAMLIT_CACHE_DIR", "/tmp/streamlit-cache")
os.environ.setdefault("STREAMLIT_BROWSER_GATHER_USAGE_STATS", "false")
# Streamlit 1.29+ëŠ” ì•„ë˜ë„ ì§€ì›
os.environ.setdefault("STREAMLIT_SERVER_FILE_WATCHER_TYPE", "none")


# ====== Ag-Grid ì˜µì…˜ ======
_AGGRID_AVAILABLE = True
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
except Exception:
    _AGGRID_AVAILABLE = False

# == debugging for 404




# í‘œ ìŠ¤í¬ë¡¤ ë†’ì´(í”½ì…€)
TABLE_SCROLL_HEIGHT = 520  # í•„ìš”í•˜ë©´ 420~680 ì‚¬ì´ë¡œ ì¡°ì ˆ

# -----------------------------
# ì •ê·œí™” & ìœ í‹¸
# -----------------------------
def naver_item_url(ticker: str | None) -> str:
    t = (ticker or "").strip()
    if not t or len(t) != 6:
        return "https://finance.naver.com"
    return f"https://finance.naver.com/item/main.naver?code={t}"

def last_close_from_horizons(rec: dict) -> float | None:
    """horizons[].price_sample[]ì—ì„œ ê°€ì¥ ìµœê·¼ close ê°’ì„ ë°˜í™˜"""
    horizons = rec.get("horizons") or []
    if not horizons:
        return None
    # end_date ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ í›„, ê°€ì¥ ë’¤ì˜ price_sample ë§ˆì§€ë§‰ close ì‚¬ìš©
    try:
        horizons = sorted(horizons, key=lambda h: h.get("end_date",""))
    except Exception:
        pass
    last_close = None
    for h in horizons:
        ps = h.get("price_sample") or []
        closes = [p.get("close") for p in ps if p.get("close") is not None]
        if closes:
            last_close = float(closes[-1])
    return last_close


def normalize_broker_name(name: str) -> str:
    if not name:
        return ""
    name = re.sub(r"\s+", "", name)           # ëª¨ë“  ê³µë°± ì œê±°
    name = re.sub(r"[&/\.#\[\]]", "_", name)  # Firestore ì˜ˆì•½ë¬¸ì ì¹˜í™˜
    name = re.sub(r"[\(\)\[\]]", "", name)    # ê´„í˜¸ë¥˜ ì œê±°
    return name.strip()

def normalize_analyst_name(name: str) -> str:
    if not name:
        return ""
    return re.sub(r"\s+", "", str(name)).strip()

def _norm_url(x: str) -> str:
    if not x:
        return ""
    s = str(x).strip()
    if s.startswith(("http://", "https://")):
        return s
    return "https://" + s

KST = pytz.timezone("Asia/Seoul")

def format_ts(ts, tz=KST):
    if not ts:
        return "-"
    try:
        dt_utc = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
    except Exception:
        try:
            dt_utc = dt.datetime.fromisoformat(str(ts))
        except Exception:
            return str(ts)
    if dt_utc.tzinfo is None:
        dt_utc = dt_utc.replace(tzinfo=dt.timezone.utc)
    return dt_utc.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S %Z")

def _aggrid_selected_empty(sel) -> bool:
    """AgGrid selected_rows ê°€ list ë˜ëŠ” DataFrame ì–‘ìª½ì„ ì•ˆì „í•˜ê²Œ ë¹„ì—ˆëŠ”ì§€ íŒë³„"""
    if isinstance(sel, list):
        return len(sel) == 0
    if isinstance(sel, pd.DataFrame):
        return sel.empty
    return True

def _aggrid_pick_first(sel):
    """AgGrid selected_rows ì—ì„œ ì²« í–‰ dictë¡œ êº¼ë‚´ê¸° (list/DF ëª¨ë‘ ì§€ì›)"""
    if isinstance(sel, list):
        return sel[0] if sel else None
    if isinstance(sel, pd.DataFrame):
        return sel.iloc[0].to_dict() if not sel.empty else None
    return None

# -----------------------------
# Firestore Client
# -----------------------------
@st.cache_resource(show_spinner=False)
def get_db():
    return firestore.Client()

# --- [ADD] analyst_reportsì—ì„œ title ë°°ì¹˜ ì¡°íšŒ (report_id -> title ë§¤í•‘) ---
@st.cache_data(show_spinner=False, ttl=300)
def fetch_titles_for_records(records: list[dict]) -> dict[str, str]:
    db = get_db()
    ids = []
    for r in records:
        rid = str(r.get("report_id") or "").strip()
        if rid:
            ids.append(rid)
    ids = sorted(set(ids))
    if not ids:
        return {}

    refs = [db.collection("analyst_reports").document(rid) for rid in ids]
    try:
        snaps = db.get_all(refs)
    except Exception:
        # ë„¤íŠ¸ì›Œí¬/ê¶Œí•œ ì˜¤ë¥˜ ì‹œ ë¹ˆ ë§¤í•‘
        return {}

    out = {}
    for s in snaps:
        if not s.exists:
            continue
        d = s.to_dict() or {}
        t = (d.get("title") or d.get("report_title") or d.get("subject") or "").strip()
        if t:
            out[s.id] = t
    return out

def _pick_title(rec: dict) -> str:
    """ë ˆì½”ë“œ ì•ˆì—ì„œ ì œëª© í›„ë³´ í•„ë“œë“¤ì„ ìš°ì„ ìˆœìœ„ë¡œ ì„ íƒ"""
    for k in ["title", "report_title", "subject", "report_subject", "headline", "name"]:
        t = (rec.get(k) or "").strip()
        if t:
            return t
    return ""

def _title_from_map_or_fields(rec: dict, title_map: dict[str, str] | None = None) -> str:
    """title_map(analyst_reports ê¸°ë°˜) ìš°ì„  â†’ í˜„ì¬ ë ˆì½”ë“œì˜ í›„ë³´ í•„ë“œ â†’ ì•ˆì „í•œ ëŒ€ì²´ì œëª©"""
    rid = str(rec.get("report_id") or "").strip()
    if title_map and rid in title_map:
        return title_map[rid]

    # ê¸°ì¡´ í›„ë³´ í•„ë“œ ë¨¼ì € ì‹œë„
    t = _pick_title(rec)
    if t:
        return t

    # ì™„ì „ ì‹¤íŒ¨ ì‹œ: ì•ˆì „í•œ ëŒ€ì²´ ì¡°í•©
    stock = (rec.get("stock") or "").strip()
    rdate = (rec.get("report_date") or "").strip()
    return f"{stock or 'ë¦¬í¬íŠ¸'} ({rdate or '-'})"

# -----------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------
@st.cache_data(show_spinner=False, ttl=60)
def load_analyst_docs(date_from: dt.date, date_to: dt.date,
                      brokers: List[str] | None, limit: int = 3000) -> List[Dict[str, Any]]:
    """evaluations/by_analyst ê·¸ë£¹ì—ì„œ ê¸°ê°„/ë¸Œë¡œì»¤ í•„í„°ë¡œ ë¬¸ì„œ ë¡œë“œ"""
    db = get_db()

    docs_raw = []
    server_filtered = False
    try:
        q = db.collection_group("by_analyst")
        want_min = date_from.isoformat() if date_from else None
        # next day for exclusive upper bound
        want_max_excl = (date_to + dt.timedelta(days=1)).isoformat() if date_to else None

        q = db.collection_group("by_analyst")
        if want_min:     q = q.where("report_date", ">=", want_min)
        if want_max_excl:q = q.where("report_date", "<",  want_max_excl)
        q = q.limit(limit)
        docs_raw = list(q.stream())
        server_filtered = True
    except Exception:
        q = db.collection_group("by_analyst").limit(limit)
        docs_raw = list(q.stream())

    broker_set = {normalize_broker_name(b) for b in (brokers or [])} or None
    out: List[Dict[str, Any]] = []
    for d in docs_raw:
        x = d.to_dict() or {}
        broker_norm = normalize_broker_name((x.get("broker") or "").strip())
        # âœ… 'í•œêµ­IRí˜‘ì˜íšŒ' ì œì™¸
        if broker_norm == "í•œêµ­IRí˜‘ì˜íšŒ" or "í‰ê°€" in broker_norm :
            continue
        if broker_set and broker_norm not in broker_set:
            continue
        x["broker"] = broker_norm
        # ì• ë„ë¦¬ìŠ¤íŠ¸ ì´ë¦„ ì •ê·œí™” ë³´ì¡° í•„ë“œ
        raw_name = (x.get("analyst_name") or x.get("analyst") or "").strip()
        x["analyst_name"] = raw_name
        x["analyst_name_norm"] = x.get("analyst_name_norm") or normalize_analyst_name(raw_name)

        # í´ë¼ì´ì–¸íŠ¸ ìª½ ê¸°ê°„ í•„í„° fallback
        if not server_filtered and (date_from or date_to):
            s = (x.get("report_date") or "").strip()
            if not s:
                continue
            try:
                d0 = dt.date.fromisoformat(s[:10])
            except Exception:
                continue
            if date_from and d0 < date_from:
                continue
            if date_to and d0 > date_to:
                continue

        # points_total ë³´ì •
        if x.get("points_total") is None and x.get("horizons"):
            x["points_total"] = sum(float(h.get("points_total_this_horizon") or 0.0) for h in x.get("horizons") or [])
        out.append(x)

    return out

@st.cache_data(show_spinner=False, ttl=60)
def load_detail_for_analyst(analyst_name: str, broker: str,
                            date_from: dt.date | None, date_to: dt.date | None,
                            limit: int = 800) -> List[Dict[str, Any]]:
    """íŠ¹ì • ì• ë„ë¦¬ìŠ¤íŠ¸(ì´ë¦„+ë¸Œë¡œì»¤)ì˜ ê·¼ê±° ë¬¸ì„œë“¤"""
    db = get_db()
    out: List[Dict[str, Any]] = []
    broker_norm = normalize_broker_name(broker)
    target_norm = normalize_analyst_name(analyst_name)

    def _q(field: str, value: str):
        q = (db.collection_group("by_analyst")
               .where("broker", "==", broker_norm)
               .where(field, "==", value))
        try:
            if date_from: q = q.where("report_date", ">=", date_from.isoformat())
            if date_to:   q = q.where("report_date", "<=", date_to.isoformat())
        except Exception:
            pass
        q = q.limit(limit)
        docs = [z.to_dict() or {} for z in q.stream()]
        for z in docs:
            z["broker"] = normalize_broker_name(z.get("broker"))
            rn = (z.get("analyst_name") or z.get("analyst") or "").strip()
            z["analyst_name"] = rn
            z["analyst_name_norm"] = z.get("analyst_name_norm") or normalize_analyst_name(rn)
        return docs

    out.extend(_q("analyst_name_norm", target_norm))
    if not out:
        out.extend(_q("analyst_name", analyst_name))
        if target_norm != analyst_name:
            out.extend(_q("analyst_name", target_norm))

    # ì¤‘ë³µ ì œê±°
    seen = set(); uniq = []
    for r in out:
        key = (str(r.get("report_id","")), str(r.get("pdf_url","")))
        if key in seen:
            continue
        seen.add(key); uniq.append(r)
    uniq.sort(key=lambda r: r.get("report_date",""), reverse=True)
    return uniq

# -----------------------------
# ì§‘ê³„ & í…Œì´ë¸” ë³€í™˜
# -----------------------------
def make_rank_table(docs: list[dict], metric: str = "avg", min_reports: int = 2) -> pd.DataFrame:
    from collections import defaultdict
    agg = defaultdict(lambda: {"sum":0.0, "n":0, "name_disp":"", "broker":"", "first":None, "last":None})
    for x in docs:
        name_raw = (x.get("analyst_name") or x.get("analyst") or "").strip()
        name_norm = x.get("analyst_name_norm") or normalize_analyst_name(name_raw)
        broker = normalize_broker_name((x.get("broker") or "").strip())
        pts = 0.0
        try: pts = float(x.get("points_total") or 0.0)
        except Exception: pass
        rdate = (x.get("report_date") or "").strip()
        key = f"{name_norm}|{broker}"
        agg[key]["sum"] += pts
        agg[key]["n"] += 1
        if not agg[key]["name_disp"]:
            agg[key]["name_disp"] = name_raw or "(unknown)"
        agg[key]["broker"] = broker
        if rdate:
            if not agg[key]["first"] or rdate < agg[key]["first"]:
                agg[key]["first"] = rdate
            if not agg[key]["last"] or rdate > agg[key]["last"]:
                agg[key]["last"]  = rdate
    rows = []
    for _, v in agg.items():
        if v["n"] < min_reports: continue
        score = (v["sum"]/v["n"]) if metric == "avg" else v["sum"]
        rows.append({
            "RankScore": round(score, 4),
            "Reports": v["n"],
            "Analyst": v["name_disp"],
            "Broker": v["broker"],
            "FirstReport": v["first"] or "",
            "LastReport": v["last"] or "",
        })
    if not rows:
        return pd.DataFrame(columns=["RankScore","Reports","Analyst","Broker","FirstReport","LastReport"])
    df = pd.DataFrame(rows).sort_values(["RankScore","Reports"], ascending=[False, False]).reset_index(drop=True)
    return df

def _price_stats(price_sample: list[dict] | None):
    if not price_sample:
        return None, None, None
    closes = [float(p.get("close")) for p in price_sample if p.get("close") is not None]
    if not closes:
        return None, None, None
    return max(closes), min(closes), closes[-1]

def _sign(x: float | None):
    if x is None: return None
    return 1 if x > 0 else (-1 if x < 0 else 0)

def _desired_from_horizon(h: Dict[str, Any]) -> int | None:
    dtg = h.get("direction_target") or {}
    desired = dtg.get("desired")
    try:
        return int(desired) if desired is not None else None
    except Exception:
        return None

def format_pos_label(desired: int | None, rating_norm: str | None) -> str:
    r = (rating_norm or "").lower()
    if desired == 1 or r == "buy":  return "ìƒìŠ¹(buy)"
    if desired == -1 or r == "sell": return "í•˜ë½(sell)"
    return "ì¤‘ë¦½(hold)"

def horizon_to_rows(rec: Dict[str, Any]) -> List[Dict[str, Any]]:
    rows = []
    horizons = rec.get("horizons") or []
    rating_norm = rec.get("rating_norm") or rec.get("rating")
    target_price = rec.get("target_price")

    for h in horizons:
        desired = _desired_from_horizon(h)
        ret = h.get("return_pct", None)  # start_close ëŒ€ë¹„ end_close ìˆ˜ìµë¥ 
        actual_sign = _sign(ret)
        correct = None
        if desired is not None and actual_sign is not None:
            if desired == 0: correct = (actual_sign == 0)
            else:            correct = (desired == actual_sign)

        sample = h.get("price_sample") or []
        max_c, min_c, last_c = _price_stats(sample)

        # ëª©í‘œê°€ ëŒ€ë¹„ ìˆ˜ìµë¥  (ë§ˆì§€ë§‰ ì¢…ê°€ ê¸°ì¤€)
        target_return_pct = None
        if target_price and target_price not in ("", 0, 0.0) and last_c:
            try:
                target_return_pct = round((float(last_c)-float(target_price))/float(target_price)*100, 3)
            except Exception:
                target_return_pct = None

        # ëª©í‘œê°€ ëŒ€ë¹„ ìµœëŒ€ ë„ë‹¬ë¥  (ìµœê³ ê°€ ê¸°ì¤€)
        max_reach_pct = None
        if target_price and target_price not in ("", 0, 0.0) and max_c:
            try:
                max_reach_pct = round((float(max_c)/float(target_price)-1)*100, 3)
            except Exception:
                max_reach_pct = None

        rows.append({
            "ë³´ê³ ì„œì¼": rec.get("report_date",""),
            "horizon(ì¼)": h.get("horizon_days"),
            "ì˜ˆì¸¡í¬ì§€ì…˜": format_pos_label(desired, rating_norm),
            "ë ˆì´íŒ…": rating_norm,
            "ì˜ˆì¸¡ëª©í‘œê°€": target_price,
            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %": None if ret is None else round(ret*100, 3),
            "ëª©í‘œê°€ëŒ€ë¹„ìˆ˜ìµë¥ %": target_return_pct,
            "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%": max_reach_pct,
            "ë°©í–¥ì •ë‹µ": None if correct is None else ("âœ…" if correct else "âŒ"),
            "ë°©í–¥ì ìˆ˜": h.get("direction_point", 0.0),
            "ëª©í‘œê·¼ì ‘ì ìˆ˜": h.get("target_proximity_point", 0.0),
            "ëª©í‘œê°€HIT": h.get("hit_target_anytime", None),
            "êµ¬ê°„ìµœê³ ì¢…ê°€": max_c,
            "êµ¬ê°„ìµœì €ì¢…ê°€": min_c,
            "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€": last_c,
            "ì¢…ëª©": rec.get("stock",""),
            "í‹°ì»¤": rec.get("ticker",""),
            "ë¦¬í¬íŠ¸PDF": rec.get("pdf_url","") or rec.get("report_url",""),
            "ìƒì„¸í˜ì´ì§€": rec.get("detail_url",""),
            "ë¦¬í¬íŠ¸ì´ì ": rec.get("points_total", 0.0),
        })
    return rows

def match_stock(rec: dict, stock_q: str | None, ticker_q: str | None) -> bool:
    if not stock_q and not ticker_q:
        return True
    if ticker_q:
        t = (rec.get("ticker") or "").strip()
        if t and str(t).lower() == str(ticker_q).lower():
            return True
    if stock_q:
        name = (rec.get("stock") or "").strip()
        if name and str(stock_q).lower() in name.lower():
            return True
    return False

def get_last_updated_from_docs(docs):
    latest = None
    for d in docs:
        ts = d.get("updated_at")
        if not ts:
            continue
        try:
            t = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
        except Exception:
            try:
                t = dt.datetime.fromisoformat(str(ts))
            except Exception:
                continue
        if latest is None or t > latest:
            latest = t
    return latest

# -----------------------------
# Streamlit UI
# -----------------------------
# st.set_page_config(page_title="í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼", layout="wide")
st.title("ğŸ“Š ì¢…ëª©ë¦¬í¬íŠ¸ ë¶„ì„")
# --- Tabs ì‹œì¸ì„± í–¥ìƒ (CSS ìŠ¤íƒ€ì¼ ì£¼ì…: ìµœì†Œ ë³€ê²½) ---
st.markdown("""
<style>
/* íƒ­ ë¬¶ìŒ í•˜ë‹¨ ê²½ê³„ì„  & ê°„ê²© */
div[data-testid="stTabs"] div[role="tablist"] {
  border-bottom: 2px solid #e9ecef;
  gap: 8px;
  padding-bottom: 2px;
  margin-bottom: 8px;
}

/* ê° íƒ­ ë²„íŠ¼: ê¸°ë³¸(ë¹„í™œì„±) ìŠ¤íƒ€ì¼ */
div[data-testid="stTabs"] button[role="tab"] {
  font-weight: 600;
  font-size: 0.95rem;
  color: #495057;
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-bottom: none; /* ì•„ë˜ìª½ì€ ì½˜í…ì¸  ì¹´ë“œì™€ ì—°ê²°ë˜ë¯€ë¡œ ì—†ì•° */
  border-top-left-radius: 8px;
  border-top-right-radius: 8px;
  padding: 10px 14px;
  box-shadow: inset 0 -3px 0 0 rgba(0,0,0,0.03);
}

/* Hover ì‹œ ì‚´ì§ ê°•ì¡° */
div[data-testid="stTabs"] button[role="tab"]:hover {
  background: #f1f3f5;
  color: #343a40;
}

/* í™œì„± íƒ­ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"] {
  background: #ffffff;
  color: #212529;
  border-color: #dee2e6;
  box-shadow: inset 0 -4px 0 0 #0d6efd; /* ìƒë‹¨ íŒŒë€ ê°•ì¡°ì„ (ë¸Œëœë“œ ì»¬ëŸ¬ ëŠë‚Œ) */
}

/* íƒ­ íŒ¨ë„(ë‚´ìš©) ì¹´ë“œ ìŠ¤íƒ€ì¼ */
div[data-testid="stTabs"] > div[data-baseweb="tab-panel"] {
  border: 1px solid #dee2e6;
  border-top: none; /* í™œì„± íƒ­ ë²„íŠ¼ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ */
  border-radius: 0 10px 10px 10px;
  padding: 16px 16px 10px 16px;
  background: #ffffff;
}

/* ì‘ì€ í™”ë©´ì—ì„œ íƒ­ ë¼ë²¨ì´ ë‘ ì¤„ì´ ë  ë•Œ ì¤„ ê°„ê²© */
div[data-testid="stTabs"] button[role="tab"] p {
  line-height: 1.1;
  margin: 0;
}
</style>
""", unsafe_allow_html=True)

# ---- ì‚¬ì´ë“œë°” ----
with st.sidebar:
    st.header("ê³µí†µ í•„í„°")
    today = dt.date.today()
    default_from = today - dt.timedelta(days=90)
    date_from = st.date_input("From date", value=default_from)
    date_to = st.date_input("To date", value=today)

    metric = st.radio("Ranking metric", ["avg", "sum"], index=0, horizontal=True)
    min_reports = st.slider("Minimum reports", 1, 20, 2, 1)
    max_docs = st.slider("Max docs to scan (by_analyst)", 500, 5000, 3000, 100)

    st.caption("â€» ê¸°ê°„/ë¸Œë¡œì»¤ë¥¼ ì¢íìˆ˜ë¡ ë¹ ë¦…ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë¦¬í¬íŠ¸ë³„ points_total í•©ê³„(ë˜ëŠ” í‰ê· )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ â†’ ì´ìš© ê°€ëŠ¥í•œ ë¸Œë¡œì»¤ ì§‘í•©/ê±´ìˆ˜ ê³„ì‚°
    base_docs = load_analyst_docs(date_from, date_to, brokers=None, limit=max_docs)
    broker_counts = {}
    for d in base_docs:
        b = normalize_broker_name((d.get("broker") or "").strip())
        if not b:
            continue
        broker_counts[b] = broker_counts.get(b, 0) + 1
    available_brokers = sorted([b for b, c in broker_counts.items() if c > 0])

    st.markdown("### ì¦ê¶Œì‚¬ ì„ íƒ")
    if not available_brokers:
        st.info("í•´ë‹¹ ê¸°ê°„ì— ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        selected_brokers = []
    else:
        labels = [f"{b} ({broker_counts[b]})" for b in available_brokers]
        selected_labels = st.multiselect("ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ ëª©ë¡", options=labels, default=labels, key="multi_brokers")
        selected_brokers = [lab.split(" (")[0] for lab in selected_labels if " (" in lab]
        if not selected_brokers:
            st.warning("ì„ íƒëœ ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# ---- ë°ì´í„° ë¡œë“œ (ë‘ íƒ­ì—ì„œ ê³µí†µ ì‚¬ìš©) ----
with st.spinner("ë¬¸ì„œ ë¡œë”© ì¤‘..."):
    docs = load_analyst_docs(date_from, date_to, selected_brokers or None, max_docs)

# âš ï¸ ë©´ì±… ì¡°í•­
st.markdown("---")
st.markdown(
    """
    âš ï¸ **ë©´ì±… ì¡°í•­ (Disclaimer)**
    ë³¸ ì‚¬ì´íŠ¸ëŠ” **í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼ í•™ìƒë“¤ì˜ ì‹¤ìŠµ ëª©ì **ìœ¼ë¡œ ì œì‘ëœ ê²ƒì…ë‹ˆë‹¤.
    ë”°ë¼ì„œ ì œê³µë˜ëŠ” ë°ì´í„°ì™€ ë­í‚¹ì€ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì–´ë– í•œ ê³µì‹ ë ¥ë„ ê°–ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ë˜í•œ, ë³¸ ì‚¬ì´íŠ¸ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **íˆ¬ì ê²°ì • ë° ê·¸ ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ ì „ì ìœ¼ë¡œ ì´ìš©ì ë³¸ì¸**ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
    ì œì‘ìëŠ” íˆ¬ì ì†ì‹¤ ë“± ì–´ë– í•œ ë²•ì  ì±…ì„ë„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """,
    unsafe_allow_html=True
)

# í‰ê°€ ë°˜ì˜ ê¸°ê°„ ë° ìµœê·¼ ê°±ì‹  ì‹œê°
date_values = [str(d.get("report_date", "")).strip() for d in docs if str(d.get("report_date","")).strip()]
if date_values:
    try:
        min_date = min(date_values)
        max_date = max(date_values)
        st.markdown(f"**í‰ê°€ ë°˜ì˜ ê¸°ê°„** {min_date} ~ {max_date}")
    except Exception:
        st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")
else:
    st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")

st.caption(f"ìµœê·¼ í‰ê°€ ë°˜ì˜ ì‹œê°(ë¬¸ì„œ ê¸°ì¤€): {format_ts(get_last_updated_from_docs(docs))}")

# -----------------------------
# ì˜¤ëŠ˜ ë²”ìœ„ ì‹ ì„ ë„ ë°°ë„ˆ + íƒ­2 ë³‘í•© ë°ì´í„° ì¤€ë¹„
# -----------------------------
today = dt.date.today()
is_today_range = (date_from and date_to and date_from <= today <= date_to)

# ì‹ ì„ ë„ ë°°ë„ˆ
if is_today_range:
    by_cnt = sum(1 for d in docs if str(d.get("report_date","")).startswith(today.isoformat()))
    db = get_db()
    ar_cnt = len(list(db.collection("analyst_reports")
                      .where("pred_time", ">=", today.isoformat())
                      .where("pred_time", "<",  (today + dt.timedelta(days=1)).isoformat())
                      .stream()))
    if ar_cnt > by_cnt:
        st.warning(f"ì˜¤ëŠ˜ ë°ì´í„° ë™ê¸°í™” ì§„í–‰ ì¤‘: by_analyst {by_cnt}ê±´ / analyst_reports {ar_cnt}ê±´")

# === íƒ­2(ì¢…ëª©ë³„ ê²€ìƒ‰) ì „ìš©: ì˜¤ëŠ˜ ë²”ìœ„ë©´ analyst_reports ë³‘í•© ===
docs_for_stock = docs[:]  # ê¸°ë³¸ì€ by_analyst ê²°ê³¼
if is_today_range:
    db = get_db()
    iso_min = date_from.isoformat()
    iso_max_excl = (date_to + dt.timedelta(days=1)).isoformat()

    try:
        q_ar = (db.collection("analyst_reports")
                  .where("pred_time", ">=", iso_min)
                  .where("pred_time", "<",  iso_max_excl)
                  .limit(max_docs))
        rows = [s.to_dict() or {} for s in q_ar.stream()]
    except Exception:
        rows = []

    # ì¤‘ë³µ ì œê±°ìš© í‚¤(ê¸°ì¡´ docs ë¨¼ì € ë°˜ì˜)
    seen = set((
        str(x.get("report_id") or ""),
        normalize_broker_name(x.get("broker") or ""),
        (x.get("analyst_name") or x.get("analyst") or "").strip(),
        str(x.get("report_date") or "")
    ) for x in docs_for_stock)

    for x in rows:
        # ë‚ ì§œ ì •ê·œí™”: ë¬¸ìì—´ YYYY-MM-DDë¡œ í†µì¼
        rd = (x.get("report_date") or x.get("pred_time") or "")
        x["report_date"] = str(rd)[:10] if rd else ""

        # ë¸Œë¡œì»¤ ì •ê·œí™” (+ ê³¼ë„ ë°°ì œ ì œê±°)
        b = normalize_broker_name(x.get("broker") or "")
        if b == "í•œêµ­IRí˜‘ì˜íšŒ":
            continue
        x["broker"] = b

        # ì• ë„ë¦¬ìŠ¤íŠ¸ í‘œì¤€í™”
        a_raw = (x.get("analyst_name") or x.get("analyst") or "").strip()
        x["analyst_name"] = a_raw
        x["analyst_name_norm"] = x.get("analyst_name_norm") or normalize_analyst_name(a_raw)

        k = (str(x.get("report_id") or ""), b, a_raw, x["report_date"])
        if k in seen:
            continue
        seen.add(k)
        docs_for_stock.append(x)

# -----------------------------
# Tabs
# -----------------------------
tab_rank, tab_stock = st.tabs(["ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ", "ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰"])

# ===============================
# íƒ­1: ë­í‚¹ë³´ë“œ (í˜ì´ì§€ë„¤ì´ì…˜ ë³µì›)
# ===============================
with tab_rank:
    st.subheader("ğŸ† Top Analysts")
    rank_df = make_rank_table(docs, metric=metric, min_reports=min_reports)

    if rank_df.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„/ë¸Œë¡œì»¤/ìµœì†Œ ë¦¬í¬íŠ¸ ìˆ˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
    else:
        # --- í˜ì´ì§€ë„¤ì´ì…˜(ë³µì›) ---
        per_page = st.selectbox("Rows per page", [10, 25, 50, 100], index=1, key="rank_rows_per_page")
        page = st.number_input("Page", 1, 9999, 1, key="rank_page")
        total_pages = max(1, math.ceil(len(rank_df) / per_page))
        page = min(page, total_pages)
        start, end = (page - 1) * per_page, (page - 1) * per_page + per_page
        show_df = rank_df.iloc[start:end].copy()
        st.caption(f"Page {page}/{total_pages} Â· Total analysts: {len(rank_df)}")

        # Ag-Grid ë Œë”ë§ (ì„ íƒ ì•ˆì •í™”)
        selected_idx = None
        _show_df = show_df.reset_index(drop=True).copy()
        ROW_H, HEAD_H, PADDING = 34, 40, 32
        GRID_H = min(HEAD_H + ROW_H * len(_show_df) + PADDING, HEAD_H + ROW_H * 25 + 400)

        if _AGGRID_AVAILABLE and not _show_df.empty:
            _show_df.insert(0, "_row", _show_df.index)
            gb = GridOptionsBuilder.from_dataframe(_show_df)
            gb.configure_selection(selection_mode="single", use_checkbox=False)
            gb.configure_grid_options(rowHeight=ROW_H, headerHeight=HEAD_H)
            gb.configure_column("_row", header_name="", hide=True)

            # â¬‡ï¸ Community ê³ ì •: ì—”í„°í”„ë¼ì´ì¦ˆ ê¸°ëŠ¥ OFF
            gb.configure_default_column(
                editable=False,
                groupable=False,
                enableValue=False,
                enableRowGroup=False,
                enablePivot=False,
            )
            try:
                gb.configure_side_bar(False)
            except Exception:
                pass

            grid = AgGrid(
                _show_df,
                gridOptions=gb.build(),
                update_mode=GridUpdateMode.SELECTION_CHANGED,
                data_return_mode=DataReturnMode.AS_INPUT,
                theme="streamlit",
                allow_unsafe_jscode=True,
                fit_columns_on_grid_load=True,
                height=GRID_H,
                enable_enterprise_modules=False,  # â† Enterprise ê²½ê³  ë°©ì§€
            )
            sel = grid.get("selected_rows", [])
            if _aggrid_selected_empty(sel):
                st.info("ìƒë‹¨ í‘œì—ì„œ í–‰ì„ í´ë¦­(ì„ íƒ)í•˜ì„¸ìš”.")
            else:
                picked = _aggrid_pick_first(sel)
                if not picked:
                    st.info("ì„ íƒ í–‰ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                else:
                    picked_name = picked.get("Analyst", "Unknown Analyst")
                    picked_broker = picked.get("Broker", "Unknown Broker")
                    st.markdown(f"### {picked_name} â€” {picked_broker}")
                    st.write(f"**Reports:** {picked.get('Reports', '-') } | **RankScore:** {picked.get('RankScore', '-') }")
                    st.write(f"**Coverage:** {picked.get('FirstReport', '-') } â†’ {picked.get('LastReport', '-') }")

                    with st.spinner("Loading evidence..."):
                        items = load_detail_for_analyst(picked_name, picked_broker, date_from, date_to)

                    if not items:
                        st.info("ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        evidence_rows: List[Dict[str, Any]] = []
                        for it in items:
                            evidence_rows.extend(horizon_to_rows(it))
                        ev_df = pd.DataFrame(evidence_rows)

                        # ì»¬ëŸ¼ ìˆœì„œ
                        wanted = [
                            "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
                            "horizon(ì¼)",
                            "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",
                            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
                            "ë¦¬í¬íŠ¸ì´ì ", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"
                        ]
                        cols = [c for c in wanted if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted]
                        ev_df = ev_df[cols]

                        # ë§í¬ ë§µ
                        if "ë¦¬í¬íŠ¸PDF" in ev_df.columns:
                            ev_df["ë¦¬í¬íŠ¸PDF"] = ev_df["ë¦¬í¬íŠ¸PDF"].map(_norm_url)
                        if "ìƒì„¸í˜ì´ì§€" in ev_df.columns:
                            ev_df["ìƒì„¸í˜ì´ì§€"] = ev_df["ìƒì„¸í˜ì´ì§€"].map(_norm_url)

                        try:
                            st.dataframe(
                                ev_df,
                                use_container_width=True,
                                column_config={
                                    "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                                    "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                                },
                            )
                        except Exception:
                            def _a(href):
                                return f'<a href="{href}" target="_blank" rel="noopener noreferrer">ì—´ê¸°</a>' if href else ""
                            html_df = ev_df.copy()
                            if "ë¦¬í¬íŠ¸PDF" in html_df.columns:
                                html_df["ë¦¬í¬íŠ¸PDF"] = html_df["ë¦¬í¬íŠ¸PDF"].map(_a)
                            if "ìƒì„¸í˜ì´ì§€" in html_df.columns:
                                html_df["ìƒì„¸í˜ì´ì§€"] = html_df["ìƒì„¸í˜ì´ì§€"].map(_a)
                            st.markdown(html_df.to_html(escape=False, index=False), unsafe_allow_html=True)
        else:
            # í´ë°± í‘œê¸°
            st.dataframe(_show_df.drop(columns=["_row"], errors="ignore") if "_row" in _show_df else _show_df,
                         use_container_width=True, height=GRID_H)
            st.info("í–‰ ì„ íƒì€ st-aggrid ì„¤ì¹˜ ì‹œ í™œì„±í™”ë©ë‹ˆë‹¤.")

# ===============================
# íƒ­2: ì¢…ëª©ë³„ ê²€ìƒ‰
# ===============================
if "stock_q" not in st.session_state:
    st.session_state["stock_q"] = ""

if "ticker_q" not in st.session_state:
    st.session_state["ticker_q"] = ""

with tab_stock:
    st.subheader("ğŸ” ì¢…ëª©ë³„ ë¦¬í¬íŠ¸ ì¡°íšŒ")
    col1, col2 = st.columns([2,1])

    # ì„¸ì…˜ ìƒíƒœ ì‚¬ìš©
    stock_q = st.text_input("ì¢…ëª©ëª…(ë¶€ë¶„ì¼ì¹˜ í—ˆìš©)", key="stock_q", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
    ticker_q = st.text_input("í‹°ì»¤(ì •í™•íˆ 6ìë¦¬)", key="ticker_q", placeholder="ì˜ˆ: 005930")

    # 1) ì…ë ¥ëœ ì¢…ëª©ëª…ìœ¼ë¡œ í›„ë³´(ì¢…ëª©ëª…,í‹°ì»¤) ëª©ë¡ ë§Œë“¤ê¸° (docs_for_stock ì‚¬ìš©)
    candidates = []
    if stock_q.strip():
        seen = set()
        for d in docs_for_stock:
            s = (d.get("stock") or "").strip()
            t = str(d.get("ticker") or "").strip()
            if s and stock_q.lower() in s.lower():
                key = (s, t)
                if key not in seen:
                    seen.add(key)
                    label = f"{s} ({t})" if t else s
                    candidates.append({"label": label, "stock": s, "ticker": t})
        candidates.sort(key=lambda x: (x["stock"], x["ticker"]))

    # 2) í›„ë³´ ì„ íƒ
    selected_stock = None
    selected_ticker = None
    if candidates:
        if len(candidates) == 1:
            selected_stock = candidates[0]["stock"]
            selected_ticker = (candidates[0]["ticker"] or "").strip() or None  # â† ë¹ˆ ê°’ì€ None ì²˜ë¦¬
            st.session_state["last_stock_pick"] = candidates[0]["label"]
        else:
            opt_labels = [c["label"] for c in candidates]
            default_index = 0
            if "last_stock_pick" in st.session_state and st.session_state["last_stock_pick"] in opt_labels:
                default_index = opt_labels.index(st.session_state["last_stock_pick"])
            pick = st.selectbox(
                "í›„ë³´ ì¢…ëª© ì„ íƒ",
                options=opt_labels,
                index=default_index,
                key="cand_pick"
            )
            st.session_state["last_stock_pick"] = pick
            _picked = next((c for c in candidates if c["label"] == pick), None)
            if _picked:
                selected_stock = _picked["stock"]
                selected_ticker = (_picked["ticker"] or "").strip() or None  # â† ë¹ˆ ê°’ì€ None ì²˜ë¦¬

    # 3) í•„í„°ë§ ë¡œì§ (docs_for_stock ì‚¬ìš©)
    if selected_stock:
        _sel_tk = (selected_ticker or "").strip()  # â† ë¹ˆ ê°’ì´ë©´ ""
        stock_docs = [
            d for d in docs_for_stock
            if (d.get("stock") or "").strip() == selected_stock
            and (not _sel_tk or str(d.get("ticker") or "").strip() == _sel_tk)
        ]
        st.markdown(f"**ê²€ìƒ‰ ëŒ€ìƒ:** {selected_stock} ({selected_ticker or '-'})")
    else:
        if not stock_q.strip() and not ticker_q.strip():
            stock_docs = docs_for_stock
            st.caption("ì „ì²´ ë¦¬í¬íŠ¸ë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤.")
        else:
            stock_docs = [d for d in docs_for_stock if match_stock(d, stock_q or None, ticker_q or None)]
            if candidates:
                st.caption(f"í›„ë³´ ì¢…ëª© {len(candidates)}ê°œ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

    st.caption(f"ê²€ìƒ‰ê²°ê³¼: {len(stock_docs)}ê±´ (ê¸°ê°„Â·ì¦ê¶Œì‚¬ í•„í„° ì ìš© í›„ ì¢…ëª© í•„í„°)")

    if not stock_docs:
        st.info("í•´ë‹¹ ì¡°ê±´ì˜ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ëª©ëª…/í‹°ì»¤ ë˜ëŠ” ê¸°ê°„/ì¦ê¶Œì‚¬ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
    else:
        from collections import defaultdict
        # ì¦ê¶Œì‚¬ ìš”ì•½
        by_broker = defaultdict(lambda: {"reports":0, "analysts":set(), "first":None, "last":None})
        for x in stock_docs:
            b = (x.get("broker") or "").strip()
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            by_broker[b]["reports"] += 1
            if a: by_broker[b]["analysts"].add(a)
            if d0:
                if by_broker[b]["first"] is None or d0 < by_broker[b]["first"]:
                    by_broker[b]["first"] = d0
                if by_broker[b]["last"] is None or d0 > by_broker[b]["last"]:
                    by_broker[b]["last"] = d0
        broker_rows = [{
            "ì¦ê¶Œì‚¬": b,
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜": len(v["analysts"]),
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for b, v in by_broker.items()]
        broker_df = pd.DataFrame(broker_rows).sort_values(["ë¦¬í¬íŠ¸ìˆ˜","ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜"], ascending=[False, False])
        st.markdown("### 1) ì¦ê¶Œì‚¬ë³„ ìš”ì•½")
        st.dataframe(broker_df, use_container_width=True)

        # ì• ë„ë¦¬ìŠ¤íŠ¸ ìš”ì•½
        st.markdown("### 2) ì• ë„ë¦¬ìŠ¤íŠ¸ë³„ ìš”ì•½")
        brokers_for_select = sorted({(x.get("broker") or "").strip() for x in stock_docs if x.get("broker")})
        pick_broker = st.selectbox("ì¦ê¶Œì‚¬ ì„ íƒ", ["(ëª¨ë‘)"] + brokers_for_select, index=0, key="stock_pick_broker")
        docs2 = stock_docs if pick_broker == "(ëª¨ë‘)" else [x for x in stock_docs if (x.get("broker") or "").strip() == pick_broker]

        by_anl = defaultdict(lambda: {"reports":0, "sum_pts":0.0, "first":None, "last":None})
        for x in docs2:
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            pts = float(x.get("points_total") or 0.0)
            by_anl[a]["reports"] += 1
            by_anl[a]["sum_pts"] += pts
            if d0:
                if by_anl[a]["first"] is None or d0 < by_anl[a]["first"]:
                    by_anl[a]["first"] = d0
                if by_anl[a]["last"] is None or d0 > by_anl[a]["last"]:
                    by_anl[a]["last"] = d0
        anl_rows = [{
            "ì• ë„ë¦¬ìŠ¤íŠ¸": a or "(unknown)",
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "í‰ê· ì ìˆ˜": round(v["sum_pts"]/v["reports"], 4) if v["reports"] else 0.0,
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for a, v in by_anl.items()]
        anl_df = pd.DataFrame(anl_rows).sort_values(["í‰ê· ì ìˆ˜","ë¦¬í¬íŠ¸ìˆ˜"], ascending=[False, False]).reset_index(drop=True)
        st.dataframe(anl_df, use_container_width=True)

        # (ë°ì´í„° êµ¬ì„±ë¶€ëŠ” ê¸°ì¡´ ê·¸ëŒ€ë¡œ ìœ ì§€)
        st.markdown("### 3) ìƒì„¸ ë‚´ì—­")
        detail_rows = []
        title_map_stock = fetch_titles_for_records(stock_docs)

        for r in stock_docs:
            title_safe = _title_from_map_or_fields(r, title_map_stock)
            if not title_safe:
                title_safe = f'{(r.get("stock") or "").strip()} ë¦¬í¬íŠ¸'

            last_close = None
            try:
                last_close = last_close_from_horizons(r)
            except:
                pass

            detail_rows.append({
                "ë¦¬í¬íŠ¸ì¼": r.get("report_date",""),
                "ì¦ê¶Œì‚¬": r.get("broker",""),
                "ì• ë„ë¦¬ìŠ¤íŠ¸": r.get("analyst_name") or r.get("analyst",""),
                "ì¢…ëª©": r.get("stock",""),
                # "í‹°ì»¤": r.get("ticker",""),
                "ë ˆì´íŒ…": r.get("rating") or r.get("rating_norm",""),
                "ëª©í‘œê°€": r.get("target_price"),
                "ë§ˆì§€ë§‰ì¢…ê°€": last_close,
                "ì œëª©": title_safe,
                # "ë¦¬í¬íŠ¸PDF": r.get("pdf_url","") or r.get("report_url",""),
                # "ìƒì„¸í˜ì´ì§€": r.get("detail_url",""),
            })

        det_df = pd.DataFrame(detail_rows).sort_values("ë¦¬í¬íŠ¸ì¼", ascending=False).reset_index(drop=True)

        if det_df.empty:
            st.info("ìƒë‹¨ í‘œì—ì„œ í–‰ì„ í´ë¦­(ì„ íƒ)í•˜ì„¸ìš”.")

        if _AGGRID_AVAILABLE and not det_df.empty:
            det_df_ag = det_df.reset_index(drop=True).copy()
            det_df_ag.insert(0, "_row", det_df_ag.index)   # ë‚´ë¶€í‚¤

            # âœ… í˜ì´ì§€ í¬ê¸° ì„ íƒ UI (ì„¸ì…˜ ìœ ì§€)
            page_size = st.selectbox(
                "ìƒì„¸ ë‚´ì—­ í˜ì´ì§€ í¬ê¸°",
                options=[25, 50, 100, 200],
                index=1,
                key="detail_page_size"
            )

            gb = GridOptionsBuilder.from_dataframe(det_df_ag)

            # ìˆ«ì ì»¬ëŸ¼ í­/íƒ€ì…(ê¸°ì¡´ ìœ ì§€)
            gb.configure_column("ëª©í‘œê°€", width=110, type=["numericColumn"])
            gb.configure_column("ë§ˆì§€ë§‰ì¢…ê°€", width=110, type=["numericColumn"])
            gb.configure_column("ë ˆì´íŒ…", width=110)

            # ë‹¨ì¼ ì„ íƒ + ë‚´ë¶€í‚¤ ìˆ¨ê¹€
            gb.configure_selection(selection_mode="single", use_checkbox=False)
            gb.configure_column("_row", header_name="", hide=True)

            # âœ… Ag-Grid ë‚´ì¥ í˜ì´ì§€ë„¤ì´ì…˜
            gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=page_size)

            # ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ë§Œ (ì—”í„°í”„ë¼ì´ì¦ˆ ê²½ê³  ë°©ì§€)
            gb.configure_default_column(
                editable=False,
                groupable=False,
                enableValue=False,
                enableRowGroup=False,
                enablePivot=False,
            )
            try:
                gb.configure_side_bar(False)
            except Exception:
                pass

            grid = AgGrid(
                det_df_ag,
                gridOptions=gb.build(),
                update_mode=GridUpdateMode.SELECTION_CHANGED,
                data_return_mode=DataReturnMode.AS_INPUT,
                theme="streamlit",
                allow_unsafe_jscode=True,
                fit_columns_on_grid_load=True,
                height=TABLE_SCROLL_HEIGHT,        # ìŠ¤í¬ë¡¤ ì˜ì—­
                key="stock_detail_main_table",
                enable_enterprise_modules=False,    # ì—”í„°í”„ë¼ì´ì¦ˆ ê²½ê³  ë°©ì§€
            )

            sel = grid.get("selected_rows", [])

            # ì„ íƒ í–‰ ì—†ìœ¼ë©´ ì²« í–‰ ìë™ ì„ íƒ(ì¬ì‹¤í–‰ì—ë„ UX ì•ˆì •)
            def _pick_first(sel):
                if isinstance(sel, list):
                    return sel[0] if sel else None
                if isinstance(sel, pd.DataFrame):
                    return sel.iloc[0].to_dict() if not sel.empty else None
                return None

            picked = _pick_first(sel)
            if not picked and not det_df_ag.empty:
                picked = det_df_ag.iloc[0].to_dict()

            if picked:
                st.markdown("---")
                st.markdown("#### ğŸ“Œ ì„ íƒ ë¦¬í¬íŠ¸ ìƒì„¸")

                p_stock  = picked.get("ì¢…ëª©","")
                p_ticker = picked.get("í‹°ì»¤","")
                if not p_ticker:
                    for _r in stock_docs:
                        t = str(_r.get("ticker") or "").strip()
                        s = (_r.get("stock") or "").strip()
                        if s == p_stock and t:
                            p_ticker = t
                            break
                p_broker = picked.get("ì¦ê¶Œì‚¬","")
                p_anl    = picked.get("ì• ë„ë¦¬ìŠ¤íŠ¸","")
                p_date   = picked.get("ë¦¬í¬íŠ¸ì¼","")
                p_pdf    = picked.get("ë¦¬í¬íŠ¸PDF","")
                p_det    = picked.get("ìƒì„¸í˜ì´ì§€","")

                c1, c2, c3, c4 = st.columns([2,2,2,2])
                c1.markdown(f"**ì¢…ëª©/í‹°ì»¤**: {p_stock} ({p_ticker or '-'})")
                c2.markdown(f"**ì¦ê¶Œì‚¬**: {p_broker}")
                c3.markdown(f"**ì• ë„ë¦¬ìŠ¤íŠ¸**: {p_anl}")
                c4.markdown(f"**ë¦¬í¬íŠ¸ì¼**: {p_date}")

                # (A) ë™ì¼ ì• ë„ë¦¬ìŠ¤íŠ¸ ê·¼ê±° â€” ë­í‚¹ íƒ­ê³¼ ê°™ì€ í˜•ì‹
                st.markdown("#### ğŸ“„ í•´ë‹¹ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ê·¼ê±° ë‚´ì—­")
                with st.spinner("ì• ë„ë¦¬ìŠ¤íŠ¸ ìƒì„¸ ë¡œë”©..."):
                    items = load_detail_for_analyst(p_anl, p_broker, date_from, date_to)
                    reports_n = len(items)
                    total_pts = 0.0
                    dates = []
                    for it in items:
                        try:
                            total_pts += float(it.get("points_total") or 0.0)
                        except Exception:
                            pass
                        rd = (it.get("report_date") or "").strip()
                        if rd: dates.append(rd)

                    rank_score = 0.0
                    if reports_n:
                        rank_score = total_pts / reports_n if metric == "avg" else total_pts

                    cov_first = min(dates) if dates else "-"
                    cov_last  = max(dates) if dates else "-"

                    st.write(f"**Reports:** {reports_n}  |  **RankScore:** {round(rank_score, 4)}  |  **Coverage:** {cov_first} â†’ {cov_last}")

                if items:
                    rows_ev = []
                    for it in items:
                        rows_ev.extend(horizon_to_rows(it))
                    ev_df = pd.DataFrame(rows_ev)

                    wanted_cols = [
                        "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
                        "horizon(ì¼)",
                        "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",
                        "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
                        "ë¦¬í¬íŠ¸ì´ì ", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"
                    ]
                    cols = [c for c in wanted_cols if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted_cols]
                    ev_df = ev_df[cols]

                    if "ë¦¬í¬íŠ¸PDF" in ev_df.columns:
                        ev_df["ë¦¬í¬íŠ¸PDF"] = ev_df["ë¦¬í¬íŠ¸PDF"].map(_norm_url)
                    if "ìƒì„¸í˜ì´ì§€" in ev_df.columns:
                        ev_df["ìƒì„¸í˜ì´ì§€"] = ev_df["ìƒì„¸í˜ì´ì§€"].map(_norm_url)

                    try:
                        st.dataframe(
                            ev_df,
                            use_container_width=True,
                            column_config={
                                "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                                "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                            },
                        )
                    except Exception:
                        def _a(href):
                            return f'<a href="{href}" target="_blank" rel="noopener noreferrer">ì—´ê¸°</a>' if href else ""
                        html_df = ev_df.copy()
                        if "ë¦¬í¬íŠ¸PDF" in html_df.columns:
                            html_df["ë¦¬í¬íŠ¸PDF"] = html_df["ë¦¬í¬íŠ¸PDF"].map(_a)
                        if "ìƒì„¸í˜ì´ì§€" in html_df.columns:
                            html_df["ìƒì„¸í˜ì´ì§€"] = html_df["ìƒì„¸í˜ì´ì§€"].map(_a)
                        st.markdown(html_df.to_html(escape=False, index=False), unsafe_allow_html=True)
                else:
                    st.info("ì„ íƒí•œ ì• ë„ë¦¬ìŠ¤íŠ¸ì˜ ìƒì„¸ ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                # (B) ì¢…ëª© ì¬ë¬´ ìŠ¤ëƒ…ìƒ· + ë„¤ì´ë²„ ë§í¬
                st.markdown("#### ğŸ“ˆ ì¢…ëª© ì •ë³´")
                st.markdown(f"[ë„¤ì´ë²„ ê¸ˆìœµ ìƒì„¸ ë³´ê¸°]({naver_item_url(p_ticker)})")

        else:
            # st.dataframe í´ë°±ì¼ ë•Œë„ ìˆ˜ë™ í˜ì´ì§€ë„¤ì´ì…˜ ì œê³µ
            per_page = st.selectbox("ìƒì„¸ ë‚´ì—­ í˜ì´ì§€ í¬ê¸°", [25, 50, 100, 200], index=1, key="detail_page_size_fallback")
            total = len(det_df)
            total_pages = (total + per_page - 1) // per_page
            page = st.number_input("í˜ì´ì§€", 1, max(1, total_pages), 1, key="detail_page_num_fallback")
            start = (page - 1) * per_page
            end = min(start + per_page, total)
            st.caption(f"Page {page}/{total_pages} Â· Rows {start+1}-{end} / {total}")
            st.dataframe(det_df.iloc[start:end], use_container_width=True, height=TABLE_SCROLL_HEIGHT)
            st.info("í–‰ í´ë¦­(ì„ íƒ)ì„ ì‚¬ìš©í•˜ë ¤ë©´ `streamlit-aggrid` ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
