# -*- coding: utf-8 -*-
"""
ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ëŒ€ì‹œë³´ë“œ (ì™„ì„±ë³¸; ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
- íƒ­1: ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ (í–‰ ì„ íƒ â†’ í•˜ë‹¨ ìƒì„¸ ê·¼ê±° í‘œì‹œ, í˜ì´ì§€ë„¤ì´ì…˜ í¬í•¨)
- íƒ­2: ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰ (ì¢…ëª©/í‹°ì»¤ë¡œ ì¡°íšŒ, ì¦ê¶Œì‚¬/ì• ë„ë¦¬ìŠ¤íŠ¸ ìš”ì•½ + ìƒì„¸)
- ë©´ì±… ì¡°í•­ / í‰ê°€ ë°˜ì˜ ê¸°ê°„ & ìµœê·¼ ë°˜ì˜ ì‹œê° í‘œê¸°
- ë¸Œë¡œì»¤/ì• ë„ë¦¬ìŠ¤íŠ¸ ê³µë°± ì œê±° ì •ê·œí™”
- Ag-Grid ì„ íƒê°’ì´ list/DF ëª¨ë‘ì—ì„œ ì•ˆì „í•˜ê²Œ ë™ì‘
"""

import math
import datetime as dt
from typing import List, Dict, Any
import re

import streamlit as st
import pandas as pd
import pytz
from google.cloud import firestore

# ====== Ag-Grid ì˜µì…˜ ======
_AGGRID_AVAILABLE = True
try:
    from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode
except Exception:
    _AGGRID_AVAILABLE = False

# -----------------------------
# ì •ê·œí™” & ìœ í‹¸
# -----------------------------
def normalize_broker_name(name: str) -> str:
    if not name:
        return ""
    name = re.sub(r"\s+", "", name)           # ëª¨ë“  ê³µë°± ì œê±°
    name = re.sub(r"[&/\.#\[\]]", "_", name)  # Firestore ì˜ˆì•½ë¬¸ì ì¹˜í™˜
    name = re.sub(r"[\(\)\[\]]", "", name)    # ê´„í˜¸ë¥˜ ì œê±°
    return name.strip()

def normalize_analyst_name(name: str) -> str:
    if not name:
        return ""
    return re.sub(r"\s+", "", str(name)).strip()

def _norm_url(x: str) -> str:
    if not x:
        return ""
    s = str(x).strip()
    if s.startswith(("http://", "https://")):
        return s
    return "https://" + s

KST = pytz.timezone("Asia/Seoul")

def format_ts(ts, tz=KST):
    if not ts:
        return "-"
    try:
        dt_utc = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
    except Exception:
        try:
            dt_utc = dt.datetime.fromisoformat(str(ts))
        except Exception:
            return str(ts)
    if dt_utc.tzinfo is None:
        dt_utc = dt_utc.replace(tzinfo=dt.timezone.utc)
    return dt_utc.astimezone(tz).strftime("%Y-%m-%d %H:%M:%S %Z")

def _aggrid_selected_empty(sel) -> bool:
    """AgGrid selected_rows ê°€ list ë˜ëŠ” DataFrame ì–‘ìª½ì„ ì•ˆì „í•˜ê²Œ ë¹„ì—ˆëŠ”ì§€ íŒë³„"""
    if isinstance(sel, list):
        return len(sel) == 0
    if isinstance(sel, pd.DataFrame):
        return sel.empty
    return True

def _aggrid_pick_first(sel):
    """AgGrid selected_rows ì—ì„œ ì²« í–‰ dictë¡œ êº¼ë‚´ê¸° (list/DF ëª¨ë‘ ì§€ì›)"""
    if isinstance(sel, list):
        return sel[0] if sel else None
    if isinstance(sel, pd.DataFrame):
        return sel.iloc[0].to_dict() if not sel.empty else None
    return None

# --- [ì¶”ê°€] horizonsì—ì„œ ê°€ì¥ ìµœê·¼(ìµœì‹  end_date) êµ¬ê°„ì˜ ë§ˆì§€ë§‰ ì¢…ê°€ ì¶”ì¶œ ---
def last_close_from_horizons(rec: dict) -> float | None:
    best_close = None
    best_key = None
    for h in (rec.get("horizons") or []):
        sample = h.get("price_sample") or []
        if not sample:
            continue
        # sample[-1]ì´ ê°€ì¥ ìµœê·¼ ì‹œì 
        last = sample[-1]
        close = last.get("close")
        # ë¹„êµ ê¸°ì¤€: end_date(ì—†ìœ¼ë©´ sampleì˜ ë§ˆì§€ë§‰ date) ë¬¸ìì—´ ë¹„êµ
        end_key = (h.get("end_date") or last.get("date") or "")
        if close is None:
            continue
        if best_key is None or str(end_key) > str(best_key):
            best_key = end_key
            try:
                best_close = float(close)
            except Exception:
                pass
    return best_close

# -----------------------------
# Firestore Client
# -----------------------------
@st.cache_resource(show_spinner=False)
def get_db():
    return firestore.Client()

# -----------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------
@st.cache_data(show_spinner=False, ttl=60)
def load_analyst_docs(date_from: dt.date, date_to: dt.date,
                      brokers: List[str] | None, limit: int = 3000) -> List[Dict[str, Any]]:
    """evaluations/by_analyst ê·¸ë£¹ì—ì„œ ê¸°ê°„/ë¸Œë¡œì»¤ í•„í„°ë¡œ ë¬¸ì„œ ë¡œë“œ"""
    db = get_db()
    want_min = date_from.isoformat() if date_from else None
    want_max = date_to.isoformat() if date_to else None

    docs_raw = []
    server_filtered = False
    try:
        q = db.collection_group("by_analyst")
        if want_min: q = q.where("report_date", ">=", want_min)
        if want_max: q = q.where("report_date", "<=", want_max)
        q = q.limit(limit)
        docs_raw = list(q.stream())
        server_filtered = True
    except Exception:
        q = db.collection_group("by_analyst").limit(limit)
        docs_raw = list(q.stream())

    broker_set = {normalize_broker_name(b) for b in (brokers or [])} or None
    out: List[Dict[str, Any]] = []
    for d in docs_raw:
        x = d.to_dict() or {}
        broker_norm = normalize_broker_name((x.get("broker") or "").strip())
        # âœ… 'í•œêµ­IRí˜‘ì˜íšŒ'ëŠ” ëª¨ë“  ì¡°íšŒì—ì„œ ì œì™¸
        if broker_norm == "í•œêµ­IRí˜‘ì˜íšŒ" or "í‰ê°€" in broker_norm :
            continue
        if broker_set and broker_norm not in broker_set:
            continue
        x["broker"] = broker_norm
        # ì• ë„ë¦¬ìŠ¤íŠ¸ ì´ë¦„ ì •ê·œí™” ë³´ì¡° í•„ë“œ
        raw_name = (x.get("analyst_name") or x.get("analyst") or "").strip()
        x["analyst_name"] = raw_name
        x["analyst_name_norm"] = x.get("analyst_name_norm") or normalize_analyst_name(raw_name)

        # í´ë¼ì´ì–¸íŠ¸ ìª½ ê¸°ê°„ í•„í„° fallback
        if not server_filtered and (date_from or date_to):
            s = (x.get("report_date") or "").strip()
            if not s:
                continue
            try:
                d0 = dt.date.fromisoformat(s[:10])
            except Exception:
                continue
            if date_from and d0 < date_from:
                continue
            if date_to and d0 > date_to:
                continue

        # points_total ë³´ì •
        if x.get("points_total") is None and x.get("horizons"):
            x["points_total"] = sum(float(h.get("points_total_this_horizon") or 0.0) for h in x.get("horizons") or [])
        out.append(x)

    return out

@st.cache_data(show_spinner=False, ttl=60)
def load_detail_for_analyst(analyst_name: str, broker: str,
                            date_from: dt.date | None, date_to: dt.date | None,
                            limit: int = 800) -> List[Dict[str, Any]]:
    """íŠ¹ì • ì• ë„ë¦¬ìŠ¤íŠ¸(ì´ë¦„+ë¸Œë¡œì»¤)ì˜ ê·¼ê±° ë¬¸ì„œë“¤"""
    db = get_db()
    out: List[Dict[str, Any]] = []
    broker_norm = normalize_broker_name(broker)
    target_norm = normalize_analyst_name(analyst_name)

    def _q(field: str, value: str):
        q = (db.collection_group("by_analyst")
               .where("broker", "==", broker_norm)
               .where(field, "==", value))
        try:
            if date_from: q = q.where("report_date", ">=", date_from.isoformat())
            if date_to:   q = q.where("report_date", "<=", date_to.isoformat())
        except Exception:
            pass
        q = q.limit(limit)
        docs = [z.to_dict() or {} for z in q.stream()]
        for z in docs:
            z["broker"] = normalize_broker_name(z.get("broker"))
            rn = (z.get("analyst_name") or z.get("analyst") or "").strip()
            z["analyst_name"] = rn
            z["analyst_name_norm"] = z.get("analyst_name_norm") or normalize_analyst_name(rn)
        return docs

    out.extend(_q("analyst_name_norm", target_norm))
    if not out:
        out.extend(_q("analyst_name", analyst_name))
        if target_norm != analyst_name:
            out.extend(_q("analyst_name", target_norm))

    # ì¤‘ë³µ ì œê±°
    seen = set(); uniq = []
    for r in out:
        key = (str(r.get("report_id","")), str(r.get("pdf_url","")))
        if key in seen:
            continue
        seen.add(key); uniq.append(r)
    uniq.sort(key=lambda r: r.get("report_date",""), reverse=True)
    return uniq

# -----------------------------
# ì§‘ê³„ & í…Œì´ë¸” ë³€í™˜
# -----------------------------
def make_rank_table(docs: list[dict], metric: str = "avg", min_reports: int = 2) -> pd.DataFrame:
    from collections import defaultdict
    agg = defaultdict(lambda: {"sum":0.0, "n":0, "name_disp":"", "broker":"", "first":None, "last":None})
    for x in docs:
        name_raw = (x.get("analyst_name") or x.get("analyst") or "").strip()
        name_norm = x.get("analyst_name_norm") or normalize_analyst_name(name_raw)
        broker = normalize_broker_name((x.get("broker") or "").strip())
        pts = 0.0
        try: pts = float(x.get("points_total") or 0.0)
        except Exception: pass
        rdate = (x.get("report_date") or "").strip()
        key = f"{name_norm}|{broker}"
        agg[key]["sum"] += pts
        agg[key]["n"] += 1
        if not agg[key]["name_disp"]:
            agg[key]["name_disp"] = name_raw or "(unknown)"
        agg[key]["broker"] = broker
        if rdate:
            if not agg[key]["first"] or rdate < agg[key]["first"]:
                agg[key]["first"] = rdate
            if not agg[key]["last"] or rdate > agg[key]["last"]:
                agg[key]["last"]  = rdate
    rows = []
    for _, v in agg.items():
        if v["n"] < min_reports: continue
        score = (v["sum"]/v["n"]) if metric == "avg" else v["sum"]
        rows.append({
            "RankScore": round(score, 4),
            "Reports": v["n"],
            "Analyst": v["name_disp"],
            "Broker": v["broker"],
            "FirstReport": v["first"] or "",
            "LastReport": v["last"] or "",
        })
    if not rows:
        return pd.DataFrame(columns=["RankScore","Reports","Analyst","Broker","FirstReport","LastReport"])
    df = pd.DataFrame(rows).sort_values(["RankScore","Reports"], ascending=[False, False]).reset_index(drop=True)
    return df

def _price_stats(price_sample: list[dict] | None):
    if not price_sample:
        return None, None, None
    closes = [float(p.get("close")) for p in price_sample if p.get("close") is not None]
    if not closes:
        return None, None, None
    return max(closes), min(closes), closes[-1]

def _sign(x: float | None):
    if x is None: return None
    return 1 if x > 0 else (-1 if x < 0 else 0)

def _desired_from_horizon(h: Dict[str, Any]) -> int | None:
    dtg = h.get("direction_target") or {}
    desired = dtg.get("desired")
    try:
        return int(desired) if desired is not None else None
    except Exception:
        return None

def format_pos_label(desired: int | None, rating_norm: str | None) -> str:
    r = (rating_norm or "").lower()
    if desired == 1 or r == "buy":  return "ìƒìŠ¹(buy)"
    if desired == -1 or r == "sell": return "í•˜ë½(sell)"
    return "ì¤‘ë¦½(hold)"

def horizon_to_rows(rec: Dict[str, Any]) -> List[Dict[str, Any]]:
    rows = []
    horizons = rec.get("horizons") or []
    rating_norm = rec.get("rating_norm") or rec.get("rating")
    target_price = rec.get("target_price")

    for h in horizons:
        desired = _desired_from_horizon(h)
        ret = h.get("return_pct", None)  # start_close ëŒ€ë¹„ end_close ìˆ˜ìµë¥ 
        actual_sign = _sign(ret)
        correct = None
        if desired is not None and actual_sign is not None:
            if desired == 0: correct = (actual_sign == 0)
            else:            correct = (desired == actual_sign)

        sample = h.get("price_sample") or []
        max_c, min_c, last_c = _price_stats(sample)

        # ëª©í‘œê°€ ëŒ€ë¹„ ìˆ˜ìµë¥  (ë§ˆì§€ë§‰ ì¢…ê°€ ê¸°ì¤€)
        target_return_pct = None
        if target_price and target_price not in ("", 0, 0.0) and last_c:
            try:
                target_return_pct = round((float(last_c)-float(target_price))/float(target_price)*100, 3)
            except Exception:
                target_return_pct = None

        # ëª©í‘œê°€ ëŒ€ë¹„ ìµœëŒ€ ë„ë‹¬ë¥  (ìµœê³ ê°€ ê¸°ì¤€)
        max_reach_pct = None
        if target_price and target_price not in ("", 0, 0.0) and max_c:
            try:
                max_reach_pct = round((float(max_c)/float(target_price)-1)*100, 3)
            except Exception:
                max_reach_pct = None

        rows.append({
            "ë³´ê³ ì„œì¼": rec.get("report_date",""),
            "horizon(ì¼)": h.get("horizon_days"),
            "ì˜ˆì¸¡í¬ì§€ì…˜": format_pos_label(desired, rating_norm),
            "ë ˆì´íŒ…": rating_norm,
            "ì˜ˆì¸¡ëª©í‘œê°€": target_price,
            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %": None if ret is None else round(ret*100, 3),
            "ëª©í‘œê°€ëŒ€ë¹„ìˆ˜ìµë¥ %": target_return_pct,
            "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%": max_reach_pct,
            "ë°©í–¥ì •ë‹µ": None if correct is None else ("âœ…" if correct else "âŒ"),
            "ë°©í–¥ì ìˆ˜": h.get("direction_point", 0.0),
            "ëª©í‘œê·¼ì ‘ì ìˆ˜": h.get("target_proximity_point", 0.0),
            "ëª©í‘œê°€HIT": h.get("hit_target_anytime", None),
            "êµ¬ê°„ìµœê³ ì¢…ê°€": max_c,
            "êµ¬ê°„ìµœì €ì¢…ê°€": min_c,
            "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€": last_c,
            "ì¢…ëª©": rec.get("stock",""),
            "í‹°ì»¤": rec.get("ticker",""),
            "ì œëª©": rec.get("title",""),
            "ë¦¬í¬íŠ¸PDF": rec.get("pdf_url","") or rec.get("report_url",""),
            "ìƒì„¸í˜ì´ì§€": rec.get("detail_url",""),
            "ë¦¬í¬íŠ¸ì´ì ": rec.get("points_total", 0.0),
        })
    return rows

def match_stock(rec: dict, stock_q: str | None, ticker_q: str | None) -> bool:
    if not stock_q and not ticker_q:
        return True
    if ticker_q:
        t = (rec.get("ticker") or "").strip()
        if t and str(t).lower() == str(ticker_q).lower():
            return True
    if stock_q:
        name = (rec.get("stock") or "").strip()
        if name and str(stock_q).lower() in name.lower():
            return True
    return False

def get_last_updated_from_docs(docs):
    latest = None
    for d in docs:
        ts = d.get("updated_at")
        if not ts:
            continue
        try:
            t = ts if isinstance(ts, dt.datetime) else ts.to_datetime()
        except Exception:
            try:
                t = dt.datetime.fromisoformat(str(ts))
            except Exception:
                continue
        if latest is None or t > latest:
            latest = t
    return latest

# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼", layout="wide")
st.title("ğŸ“Š ì¢…ëª©ë¦¬í¬íŠ¸ ë¶„ì„")
# --- Tabs ì‹œì¸ì„± í–¥ìƒ (CSS ìŠ¤íƒ€ì¼ ì£¼ì…: ìµœì†Œ ë³€ê²½) ---
st.markdown("""
<style>
/* íƒ­ ë¬¶ìŒ í•˜ë‹¨ ê²½ê³„ì„  & ê°„ê²© */
div[data-testid="stTabs"] div[role="tablist"] {
  border-bottom: 2px solid #e9ecef;
  gap: 8px;
  padding-bottom: 2px;
  margin-bottom: 8px;
}

/* ê° íƒ­ ë²„íŠ¼: ê¸°ë³¸(ë¹„í™œì„±) ìŠ¤íƒ€ì¼ */
div[data-testid="stTabs"] button[role="tab"] {
  font-weight: 600;
  font-size: 0.95rem;
  color: #495057;
  background: #f8f9fa;
  border: 1px solid #e9ecef;
  border-bottom: none; /* ì•„ë˜ìª½ì€ ì½˜í…ì¸  ì¹´ë“œì™€ ì—°ê²°ë˜ë¯€ë¡œ ì—†ì•° */
  border-top-left-radius: 8px;
  border-top-right-radius: 8px;
  padding: 10px 14px;
  box-shadow: inset 0 -3px 0 0 rgba(0,0,0,0.03);
}

/* Hover ì‹œ ì‚´ì§ ê°•ì¡° */
div[data-testid="stTabs"] button[role="tab"]:hover {
  background: #f1f3f5;
  color: #343a40;
}

/* í™œì„± íƒ­ */
div[data-testid="stTabs"] button[role="tab"][aria-selected="true"] {
  background: #ffffff;
  color: #212529;
  border-color: #dee2e6;
  box-shadow: inset 0 -4px 0 0 #0d6efd; /* ìƒë‹¨ íŒŒë€ ê°•ì¡°ì„ (ë¸Œëœë“œ ì»¬ëŸ¬ ëŠë‚Œ) */
}

/* íƒ­ íŒ¨ë„(ë‚´ìš©) ì¹´ë“œ ìŠ¤íƒ€ì¼ */
div[data-testid="stTabs"] > div[data-baseweb="tab-panel"] {
  border: 1px solid #dee2e6;
  border-top: none; /* í™œì„± íƒ­ ë²„íŠ¼ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ */
  border-radius: 0 10px 10px 10px;
  padding: 16px 16px 10px 16px;
  background: #ffffff;
}

/* ì‘ì€ í™”ë©´ì—ì„œ íƒ­ ë¼ë²¨ì´ ë‘ ì¤„ì´ ë  ë•Œ ì¤„ ê°„ê²© */
div[data-testid="stTabs"] button[role="tab"] p {
  line-height: 1.1;
  margin: 0;
}
</style>
""", unsafe_allow_html=True)

# ---- ì‚¬ì´ë“œë°” ----
with st.sidebar:
    st.header("ê³µí†µ í•„í„°")
    today = dt.date.today()
    default_from = today - dt.timedelta(days=90)
    date_from = st.date_input("From date", value=default_from)
    date_to = st.date_input("To date", value=today)

    metric = st.radio("Ranking metric", ["avg", "sum"], index=0, horizontal=True)
    min_reports = st.slider("Minimum reports", 1, 20, 2, 1)
    max_docs = st.slider("Max docs to scan (by_analyst)", 500, 5000, 3000, 100)

    st.caption("â€» ê¸°ê°„/ë¸Œë¡œì»¤ë¥¼ ì¢íìˆ˜ë¡ ë¹ ë¦…ë‹ˆë‹¤. ì ìˆ˜ëŠ” ë¦¬í¬íŠ¸ë³„ points_total í•©ê³„(ë˜ëŠ” í‰ê· )ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    # ê¸°ê°„ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ â†’ ì´ìš© ê°€ëŠ¥í•œ ë¸Œë¡œì»¤ ì§‘í•©/ê±´ìˆ˜ ê³„ì‚°
    base_docs = load_analyst_docs(date_from, date_to, brokers=None, limit=max_docs)
    broker_counts = {}
    for d in base_docs:
        b = normalize_broker_name((d.get("broker") or "").strip())
        if not b:
            continue
        broker_counts[b] = broker_counts.get(b, 0) + 1
    available_brokers = sorted([b for b, c in broker_counts.items() if c > 0])

    st.markdown("### ì¦ê¶Œì‚¬ ì„ íƒ")
    if not available_brokers:
        st.info("í•´ë‹¹ ê¸°ê°„ì— ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì„ ì¡°ì •í•´ ì£¼ì„¸ìš”.")
        selected_brokers = []
    else:
        labels = [f"{b} ({broker_counts[b]})" for b in available_brokers]
        selected_labels = st.multiselect("ë¦¬í¬íŠ¸ê°€ ì¡´ì¬í•˜ëŠ” ì¦ê¶Œì‚¬ ëª©ë¡", options=labels, default=labels, key="multi_brokers")
        selected_brokers = [lab.split(" (")[0] for lab in selected_labels if " (" in lab]
        if not selected_brokers:
            st.warning("ì„ íƒëœ ì¦ê¶Œì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")

# ---- ë°ì´í„° ë¡œë“œ (ë‘ íƒ­ì—ì„œ ê³µí†µ ì‚¬ìš©) ----
with st.spinner("ë¬¸ì„œ ë¡œë”© ì¤‘..."):
    docs = load_analyst_docs(date_from, date_to, selected_brokers or None, max_docs)

# âš ï¸ ë©´ì±… ì¡°í•­
st.markdown("---")
st.markdown(
    """
    âš ï¸ **ë©´ì±… ì¡°í•­ (Disclaimer)**
    ë³¸ ì‚¬ì´íŠ¸ëŠ” **í•œêµ­í´ë¦¬í…ëŒ€í•™ ìŠ¤ë§ˆíŠ¸ê¸ˆìœµê³¼ í•™ìƒë“¤ì˜ ì‹¤ìŠµ ëª©ì **ìœ¼ë¡œ ì œì‘ëœ ê²ƒì…ë‹ˆë‹¤.
    ë”°ë¼ì„œ ì œê³µë˜ëŠ” ë°ì´í„°ì™€ ë­í‚¹ì€ ì˜¤ë¥˜ê°€ ìˆì„ ìˆ˜ ìˆìœ¼ë©°, ì–´ë– í•œ ê³µì‹ ë ¥ë„ ê°–ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ë˜í•œ, ë³¸ ì‚¬ì´íŠ¸ì˜ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ **íˆ¬ì ê²°ì • ë° ê·¸ ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ ì „ì ìœ¼ë¡œ ì´ìš©ì ë³¸ì¸**ì—ê²Œ ìˆìŠµë‹ˆë‹¤.
    ì œì‘ìëŠ” íˆ¬ì ì†ì‹¤ ë“± ì–´ë– í•œ ë²•ì  ì±…ì„ë„ ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """,
    unsafe_allow_html=True
)

# í‰ê°€ ë°˜ì˜ ê¸°ê°„ ë° ìµœê·¼ ê°±ì‹  ì‹œê°
date_values = [str(d.get("report_date", "")).strip() for d in docs if str(d.get("report_date","")).strip()]
if date_values:
    try:
        min_date = min(date_values)
        max_date = max(date_values)
        st.markdown(f"**í‰ê°€ ë°˜ì˜ ê¸°ê°„** {min_date} ~ {max_date}")
    except Exception:
        st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")
else:
    st.markdown("**í‰ê°€ ë°˜ì˜ ê¸°ê°„** - ~ -")

st.caption(f"ìµœê·¼ í‰ê°€ ë°˜ì˜ ì‹œê°(ë¬¸ì„œ ê¸°ì¤€): {format_ts(get_last_updated_from_docs(docs))}")

# -----------------------------
# Tabs
# -----------------------------
tab_rank, tab_stock = st.tabs(["ğŸ† ì¢…ëª©ë¦¬í¬íŠ¸ í‰ê°€ ë­í‚¹ë³´ë“œ", "ğŸ” ì¢…ëª©ë³„ ê²€ìƒ‰"])

# ===============================
# íƒ­1: ë­í‚¹ë³´ë“œ (í˜ì´ì§€ë„¤ì´ì…˜ ë³µì›)
# ===============================
with tab_rank:
    st.subheader("ğŸ† Top Analysts")
    rank_df = make_rank_table(docs, metric=metric, min_reports=min_reports)

    if rank_df.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„/ë¸Œë¡œì»¤/ìµœì†Œ ë¦¬í¬íŠ¸ ìˆ˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
    else:
        # --- í˜ì´ì§€ë„¤ì´ì…˜(ë³µì›) ---
        per_page = st.selectbox("Rows per page", [10, 25, 50, 100], index=1, key="rank_rows_per_page")
        page = st.number_input("Page", 1, 9999, 1, key="rank_page")
        total_pages = max(1, math.ceil(len(rank_df) / per_page))
        page = min(page, total_pages)
        start, end = (page - 1) * per_page, (page - 1) * per_page + per_page
        show_df = rank_df.iloc[start:end].copy()
        st.caption(f"Page {page}/{total_pages} Â· Total analysts: {len(rank_df)}")

        # Ag-Grid ë Œë”ë§ (ì„ íƒ ì•ˆì •í™”)
        selected_idx = None
        _show_df = show_df.reset_index(drop=True).copy()
        ROW_H, HEAD_H, PADDING = 34, 40, 32
        GRID_H = min(HEAD_H + ROW_H * len(_show_df) + PADDING, HEAD_H + ROW_H * 25 + 400)

        if _AGGRID_AVAILABLE and not _show_df.empty:
            _show_df.insert(0, "_row", _show_df.index)
            gb = GridOptionsBuilder.from_dataframe(_show_df)
            gb.configure_selection(selection_mode="single", use_checkbox=False)
            gb.configure_grid_options(rowHeight=ROW_H, headerHeight=HEAD_H)
            gb.configure_column("_row", header_name="", hide=True)
            grid = AgGrid(
                _show_df,
                gridOptions=gb.build(),
                update_mode=GridUpdateMode.SELECTION_CHANGED,
                data_return_mode=DataReturnMode.AS_INPUT,
                theme="streamlit",
                allow_unsafe_jscode=True,
                fit_columns_on_grid_load=True,
                height=GRID_H,
            )
            sel = grid.get("selected_rows", [])
            if _aggrid_selected_empty(sel):
                st.info("ìƒë‹¨ í‘œì—ì„œ í–‰ì„ í´ë¦­(ì„ íƒ)í•˜ì„¸ìš”.")
            else:
                picked = _aggrid_pick_first(sel)
                if not picked:
                    st.info("ì„ íƒ í–‰ì„ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ ì£¼ì„¸ìš”.")
                else:
                    picked_name = picked.get("Analyst", "Unknown Analyst")
                    picked_broker = picked.get("Broker", "Unknown Broker")
                    st.markdown(f"### {picked_name} â€” {picked_broker}")
                    st.write(f"**Reports:** {picked.get('Reports', '-') } | **RankScore:** {picked.get('RankScore', '-') }")
                    # ì»¤ë²„ë¦¬ì§€(ì„ íƒëœ í˜ì´ì§• ë‚´ first/last ëŒ€ì‹  ì „ì²´ í…Œì´ë¸” ê¸°ì¤€ í‘œê¸° í•„ìš” ì‹œ rank_dfì—ì„œ ì°¾ì„ ìˆ˜ë„ ìˆìŒ)
                    # ê°„ë‹¨íˆ í˜„ì¬ ìŠ¬ë¼ì´ìŠ¤ ê°’ìœ¼ë¡œ í‘œê¸°
                    st.write(f"**Coverage:** {picked.get('FirstReport', '-') } â†’ {picked.get('LastReport', '-') }")

                    with st.spinner("Loading evidence..."):
                        items = load_detail_for_analyst(picked_name, picked_broker, date_from, date_to)

                    if not items:
                        st.info("ìƒì„¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        evidence_rows: List[Dict[str, Any]] = []
                        for it in items:
                            evidence_rows.extend(horizon_to_rows(it))
                        ev_df = pd.DataFrame(evidence_rows)

                        # ì»¬ëŸ¼ ìˆœì„œ
                        wanted = [
                            "ë³´ê³ ì„œì¼", "ì¢…ëª©", "í‹°ì»¤", "ë ˆì´íŒ…", "ì˜ˆì¸¡í¬ì§€ì…˜", "ì˜ˆì¸¡ëª©í‘œê°€",
                            "horizon(ì¼)",
                            "êµ¬ê°„ìµœê³ ì¢…ê°€", "êµ¬ê°„ìµœì €ì¢…ê°€", "êµ¬ê°„ë§ˆì§€ë§‰ì¢…ê°€", "ëª©í‘œê°€ëŒ€ë¹„ìµœëŒ€ë„ë‹¬%",
                            "ë¦¬í¬íŠ¸ì¼ì— ë§¤ìˆ˜í–ˆì„ê²½ìš° ìˆ˜ìµë¥ %", "ë°©í–¥ì •ë‹µ", "ë°©í–¥ì ìˆ˜", "ëª©í‘œê·¼ì ‘ì ìˆ˜", "ëª©í‘œê°€HIT",
                            "ë¦¬í¬íŠ¸ì´ì ", "ì œëª©", "ë¦¬í¬íŠ¸PDF", "ìƒì„¸í˜ì´ì§€"
                        ]
                        cols = [c for c in wanted if c in ev_df.columns] + [c for c in ev_df.columns if c not in wanted]
                        ev_df = ev_df[cols]

                        # ë§í¬ ë§µ
                        if "ë¦¬í¬íŠ¸PDF" in ev_df.columns:
                            ev_df["ë¦¬í¬íŠ¸PDF"] = ev_df["ë¦¬í¬íŠ¸PDF"].map(_norm_url)
                        if "ìƒì„¸í˜ì´ì§€" in ev_df.columns:
                            ev_df["ìƒì„¸í˜ì´ì§€"] = ev_df["ìƒì„¸í˜ì´ì§€"].map(_norm_url)

                        try:
                            st.dataframe(
                                ev_df,
                                use_container_width=True,
                                column_config={
                                    "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                                    "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                                },
                            )
                        except Exception:
                            def _a(href):
                                return f'<a href="{href}" target="_blank" rel="noopener noreferrer">ì—´ê¸°</a>' if href else ""
                            html_df = ev_df.copy()
                            if "ë¦¬í¬íŠ¸PDF" in html_df.columns:
                                html_df["ë¦¬í¬íŠ¸PDF"] = html_df["ë¦¬í¬íŠ¸PDF"].map(_a)
                            if "ìƒì„¸í˜ì´ì§€" in html_df.columns:
                                html_df["ìƒì„¸í˜ì´ì§€"] = html_df["ìƒì„¸í˜ì´ì§€"].map(_a)
                            st.markdown(html_df.to_html(escape=False, index=False), unsafe_allow_html=True)
        else:
            # í´ë°± í‘œê¸°
            st.dataframe(_show_df.drop(columns=["_row"], errors="ignore") if "_row" in _show_df else _show_df,
                         use_container_width=True, height=GRID_H)
            st.info("í–‰ ì„ íƒì€ st-aggrid ì„¤ì¹˜ ì‹œ í™œì„±í™”ë©ë‹ˆë‹¤.")

# ===============================
# íƒ­2: ì¢…ëª©ë³„ ê²€ìƒ‰
# ===============================
# with tab_stock:
#     st.subheader("ğŸ” ì¢…ëª©ë³„ ë¦¬í¬íŠ¸ ì¡°íšŒ")
#     col1, col2 = st.columns([2,1])
#     with col1:
#         stock_q = st.text_input("ì¢…ëª©ëª…(ë¶€ë¶„ì¼ì¹˜ í—ˆìš©)", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
#     with col2:
#         ticker_q = st.text_input("í‹°ì»¤(ì •í™•íˆ 6ìë¦¬)", value="", placeholder="ì˜ˆ: 005930")

#     # âœ… [ì¶”ê°€] ê¸°ë³¸ê°’ì´ ì‚¼ì„±ì „ìì¼ ë•Œ ìë™ìœ¼ë¡œ í•„í„° ì ìš©ë˜ë„ë¡ ë³´ì •
#     # if not stock_q.strip():
#     #     stock_q = "ì‚¼ì„±ì „ì"

#     stock_docs = [d for d in docs if match_stock(d, stock_q or None, ticker_q or None)]
#     st.caption(f"ê²€ìƒ‰ê²°ê³¼: {len(stock_docs)}ê±´ (ê¸°ê°„Â·ì¦ê¶Œì‚¬ í•„í„° ì ìš© í›„ ì¢…ëª© í•„í„°)")
with tab_stock:
    st.subheader("ğŸ” ì¢…ëª©ë³„ ë¦¬í¬íŠ¸ ì¡°íšŒ")
    col1, col2 = st.columns([2,1])
    with col1:
        stock_q = st.text_input("ì¢…ëª©ëª…(ë¶€ë¶„ì¼ì¹˜ í—ˆìš©)", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì")
    with col2:
        ticker_q = st.text_input("í‹°ì»¤(ì •í™•íˆ 6ìë¦¬)", value="", placeholder="ì˜ˆ: 005930")

    # 1) ì…ë ¥ëœ ì¢…ëª©ëª…ìœ¼ë¡œ í›„ë³´(ì¢…ëª©ëª…,í‹°ì»¤) ëª©ë¡ ë§Œë“¤ê¸°
    #    - docsì—ì„œ ë¶€ë¶„ì¼ì¹˜ë¡œ í›„ë³´ ìˆ˜ì§‘
    candidates = []
    if stock_q.strip():
        seen = set()
        for d in docs:
            s = (d.get("stock") or "").strip()
            t = str(d.get("ticker") or "").strip()
            if s and stock_q.lower() in s.lower():
                key = (s, t)
                if key not in seen:
                    seen.add(key)
                    label = f"{s} ({t})" if t else s
                    candidates.append({"label": label, "stock": s, "ticker": t})
        # ì •ë ¬(ê°€ë…ì„±)
        candidates.sort(key=lambda x: (x["stock"], x["ticker"]))

    # 2) í›„ë³´ê°€ ì—¬ëŸ¬ ê°œë©´ ì„ íƒ ë°•ìŠ¤ ì œê³µ(ì‚¬ìš© í¸ì˜ â†‘)
    selected_stock = None
    selected_ticker = None
    if candidates:
      if len(candidates) == 1:
          selected_stock = candidates[0]["stock"]
          selected_ticker = candidates[0]["ticker"]
          st.session_state["last_stock_pick"] = candidates[0]["label"]
      else:
          opt_labels = [c["label"] for c in candidates]

          # âœ… ê¸°ì¡´ ì„ íƒê°’ì´ ì„¸ì…˜ì— ìˆìœ¼ë©´ ë³µì›
          default_index = 0
          if "last_stock_pick" in st.session_state and st.session_state["last_stock_pick"] in opt_labels:
              default_index = opt_labels.index(st.session_state["last_stock_pick"])

          # âœ… ì‚¬ìš©ìê°€ ë°”ê¾¼ ì„ íƒê°’ì„ ì„¸ì…˜ì— ì €ì¥
          pick = st.selectbox(
              "í›„ë³´ ì¢…ëª© ì„ íƒ",
              options=opt_labels,
              index=default_index,
              key="cand_pick"
          )
          st.session_state["last_stock_pick"] = pick  # ìµœì‹  ì„ íƒ ìœ ì§€

          _picked = next((c for c in candidates if c["label"] == pick), None)
          if _picked:
              selected_stock = _picked["stock"]
              selected_ticker = _picked["ticker"]


    # 3) í•„í„°ë§ ë¡œì§
    #    - í›„ë³´ê°€ ì„ íƒë˜ì—ˆìœ¼ë©´ 'ì •í™•íˆ ê·¸ ì¢…ëª©/í‹°ì»¤'ë¡œ í•„í„°
    #    - ì•„ë‹ˆë©´ ê¸°ì¡´ ë¶€ë¶„ì¼ì¹˜/ì •í™• ë§¤ì¹­ ë¡œì§ ì‚¬ìš©
    if selected_stock:
        stock_docs = [
            d for d in docs
            if (d.get("stock") or "").strip() == selected_stock
            and (selected_ticker is None or str(d.get("ticker") or "").strip() == selected_ticker)
        ]
        # ìƒë‹¨ì— ê²€ìƒ‰ ëŒ€ìƒ í‘œì‹œ
        st.markdown(f"**ê²€ìƒ‰ ëŒ€ìƒ:** {selected_stock} ({selected_ticker or '-'})")
    else:
        stock_docs = [d for d in docs if match_stock(d, stock_q or None, ticker_q or None)]
        # í›„ë³´ ìˆ˜ ì•ˆë‚´(ì„ íƒ ì „)
        if candidates:
            st.caption(f"í›„ë³´ ì¢…ëª© {len(candidates)}ê°œ ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

    st.caption(f"ê²€ìƒ‰ê²°ê³¼: {len(stock_docs)}ê±´ (ê¸°ê°„Â·ì¦ê¶Œì‚¬ í•„í„° ì ìš© í›„ ì¢…ëª© í•„í„°)")


    if not stock_docs:
        st.info("í•´ë‹¹ ì¡°ê±´ì˜ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢…ëª©ëª…/í‹°ì»¤ ë˜ëŠ” ê¸°ê°„/ì¦ê¶Œì‚¬ë¥¼ ì¡°ì •í•´ ë³´ì„¸ìš”.")
    else:
        from collections import defaultdict
        # ì¦ê¶Œì‚¬ ìš”ì•½
        by_broker = defaultdict(lambda: {"reports":0, "analysts":set(), "first":None, "last":None})
        for x in stock_docs:
            b = (x.get("broker") or "").strip()
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            by_broker[b]["reports"] += 1
            if a: by_broker[b]["analysts"].add(a)
            if d0:
                if by_broker[b]["first"] is None or d0 < by_broker[b]["first"]:
                    by_broker[b]["first"] = d0
                if by_broker[b]["last"] is None or d0 > by_broker[b]["last"]:
                    by_broker[b]["last"] = d0
        broker_rows = [{
            "ì¦ê¶Œì‚¬": b,
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜": len(v["analysts"]),
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for b, v in by_broker.items()]
        broker_df = pd.DataFrame(broker_rows).sort_values(["ë¦¬í¬íŠ¸ìˆ˜","ì• ë„ë¦¬ìŠ¤íŠ¸ìˆ˜"], ascending=[False, False])
        st.markdown("### 1) ì¦ê¶Œì‚¬ë³„ ìš”ì•½")
        st.dataframe(broker_df, use_container_width=True)

        # ì• ë„ë¦¬ìŠ¤íŠ¸ ìš”ì•½
        st.markdown("### 2) ì• ë„ë¦¬ìŠ¤íŠ¸ë³„ ìš”ì•½")
        brokers_for_select = sorted({(x.get("broker") or "").strip() for x in stock_docs if x.get("broker")})
        pick_broker = st.selectbox("ì¦ê¶Œì‚¬ ì„ íƒ", ["(ëª¨ë‘)"] + brokers_for_select, index=0, key="stock_pick_broker")
        docs2 = stock_docs if pick_broker == "(ëª¨ë‘)" else [x for x in stock_docs if (x.get("broker") or "").strip() == pick_broker]

        by_anl = defaultdict(lambda: {"reports":0, "sum_pts":0.0, "first":None, "last":None})
        for x in docs2:
            a = (x.get("analyst_name") or x.get("analyst") or "").strip()
            d0 = (x.get("report_date") or "").strip()
            pts = float(x.get("points_total") or 0.0)
            by_anl[a]["reports"] += 1
            by_anl[a]["sum_pts"] += pts
            if d0:
                if by_anl[a]["first"] is None or d0 < by_anl[a]["first"]:
                    by_anl[a]["first"] = d0
                if by_anl[a]["last"] is None or d0 > by_anl[a]["last"]:
                    by_anl[a]["last"] = d0
        anl_rows = [{
            "ì• ë„ë¦¬ìŠ¤íŠ¸": a or "(unknown)",
            "ë¦¬í¬íŠ¸ìˆ˜": v["reports"],
            "í‰ê· ì ìˆ˜": round(v["sum_pts"]/v["reports"], 4) if v["reports"] else 0.0,
            "ìµœì´ˆë¦¬í¬íŠ¸ì¼": v["first"] or "",
            "ìµœì¢…ë¦¬í¬íŠ¸ì¼": v["last"] or "",
        } for a, v in by_anl.items()]
        anl_df = pd.DataFrame(anl_rows).sort_values(["í‰ê· ì ìˆ˜","ë¦¬í¬íŠ¸ìˆ˜"], ascending=[False, False]).reset_index(drop=True)
        st.dataframe(anl_df, use_container_width=True)

        # ìƒì„¸
        st.markdown("### 3) ìƒì„¸ ë‚´ì—­")
        detail_rows = []
        for r in stock_docs:
            # âœ… ì œëª© ë³´ê°•: ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ë¥¸ í‚¤/ëŒ€ì²´ë¬¸êµ¬ë¡œ ë³´ì™„
            title_safe = (r.get("title")
                          or r.get("pdf_title")
                          or r.get("detail_title")
                          or "").strip()
            if not title_safe:
                title_safe = f'{(r.get("stock") or "").strip()} ë¦¬í¬íŠ¸'

            # âœ… ë§ˆì§€ë§‰ ì¢…ê°€ ì¶”ì¶œ
            last_close = last_close_from_horizons(r)

            detail_rows.append({
                "ë¦¬í¬íŠ¸ì¼": r.get("report_date",""),
                "ì¦ê¶Œì‚¬": r.get("broker",""),
                "ì• ë„ë¦¬ìŠ¤íŠ¸": r.get("analyst_name") or r.get("analyst",""),
                "ì¢…ëª©": r.get("stock",""),          # (ì´ì „ ìˆ˜ì •ì—ì„œ ì¶”ê°€ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
                "í‹°ì»¤": r.get("ticker",""),         # (ì´ì „ ìˆ˜ì •ì—ì„œ ì¶”ê°€ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ)
                "ë ˆì´íŒ…": r.get("rating") or r.get("rating_norm",""),
                "ëª©í‘œê°€": r.get("target_price"),
                "ë§ˆì§€ë§‰ì¢…ê°€": last_close,            # âœ… ìƒˆ ì»¬ëŸ¼ ì¶”ê°€ (ëª©í‘œê°€ ì˜†)
                "ì œëª©": title_safe,                  # âœ… ë¹ˆ ì œëª© ë³´ì •
                "ë¦¬í¬íŠ¸PDF": r.get("pdf_url","") or r.get("report_url",""),
                "ìƒì„¸í˜ì´ì§€": r.get("detail_url",""),
            })

        det_df = pd.DataFrame(detail_rows).sort_values("ë¦¬í¬íŠ¸ì¼", ascending=False).reset_index(drop=True)

        if "ë¦¬í¬íŠ¸PDF" in det_df.columns:
            det_df["ë¦¬í¬íŠ¸PDF"] = det_df["ë¦¬í¬íŠ¸PDF"].map(_norm_url)
        if "ìƒì„¸í˜ì´ì§€" in det_df.columns:
            det_df["ìƒì„¸í˜ì´ì§€"] = det_df["ìƒì„¸í˜ì´ì§€"].map(_norm_url)
        try:
            st.dataframe(
                det_df,
                use_container_width=True,
                column_config={
                    "ë¦¬í¬íŠ¸PDF": st.column_config.LinkColumn(label="ë¦¬í¬íŠ¸PDF", display_text="ì—´ê¸°"),
                    "ìƒì„¸í˜ì´ì§€": st.column_config.LinkColumn(label="ìƒì„¸í˜ì´ì§€", display_text="ì—´ê¸°"),
                }
            )
        except Exception:
            def _a(href):
                return f'<a href="{href}" target="_blank" rel="noopener noreferrer">ì—´ê¸°</a>' if href else ""
            html_df = det_df.copy()
            if "ë¦¬í¬íŠ¸PDF" in html_df.columns:
                html_df["ë¦¬í¬íŠ¸PDF"] = html_df["ë¦¬í¬íŠ¸PDF"].map(_a)
            if "ìƒì„¸í˜ì´ì§€" in html_df.columns:
                html_df["ìƒì„¸í˜ì´ì§€"] = html_df["ìƒì„¸í˜ì´ì§€"].map(_a)
            st.markdown(html_df.to_html(escape=False, index=False), unsafe_allow_html=True)
